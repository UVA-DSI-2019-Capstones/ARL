{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as accuracy\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding_lookup(train_data):\n",
    "    ''' Lookup sentence embedding using tf_hub'''\n",
    "    module = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "    \n",
    "    module(train_data)\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings = np.array(session.run(module(inputs=train_data)))\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_prep_reg():\n",
    "    ''' Read data from a csv file and use keras preprocessing to create \n",
    "    data matrix with sequence of integers for each sentence padded with \n",
    "    zeros'''\n",
    "    tokenizer = Tokenizer()\n",
    "    # Read data from csv file\n",
    "    df = pd.read_csv(\"C:/Users/SODIQ-PC/Desktop/Capstone_1819/turk_data.csv\",sep=',')\n",
    "\n",
    "    # Extract the response column from data\n",
    "    data = df['turk_response_text']\n",
    "    label = np.array(df[['1','2','3']])\n",
    "    \n",
    "    y1 = label[:,0]\n",
    "    y2 = label[:,1]\n",
    "    y3 = label[:,2]\n",
    "    \n",
    "    # convert each sentence to a string and make all data into a list\n",
    "    corpus = [str(data[i]).lower() for i in range(len(data))]\n",
    "    \n",
    "    #tokenize the corpus removing punctuations and get unique vocabulary of of corpus\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    corpus_emb = sentence_embedding_lookup(corpus)\n",
    "    \n",
    "    # split data into train and test set\n",
    "    x1_train, x1_test, y1_train, y1_test = train_test_split(corpus_emb, y1, test_size=0.2, random_state=10)\n",
    "    # split data into train and test set\n",
    "    x2_train, x2_test, y2_train, y2_test = train_test_split(corpus_emb, y2, test_size=0.2, random_state=10)\n",
    "    # split data into train and test set\n",
    "    x3_train, x3_test, y3_train, y3_test = train_test_split(corpus_emb, y3, test_size=0.2, random_state=10)\n",
    "\n",
    "    return x1_train, x1_test, y1_train, y1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(train_data):\n",
    "    '''Create a baseline model using DNN regression '''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 512, activation = 'relu', input_dim = train_data.shape[1]))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 10, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using C:\\Users\\SODIQ-PC\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = dataset_prep_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.90219116e-01,  8.55127797e-02,  1.35206953e-01,\n",
       "         1.79620519e-01,  9.19984952e-02, -2.64803320e-02,\n",
       "         6.17542937e-02, -1.35534346e-01, -6.32471517e-02,\n",
       "         1.74567886e-02,  1.02215987e-02, -1.07701704e-01,\n",
       "         1.04338536e-02, -1.87209398e-01, -7.08149001e-02,\n",
       "         4.47419249e-02,  4.69313636e-02,  7.14493021e-02,\n",
       "        -9.01800320e-02,  3.83826256e-01,  8.11571553e-02,\n",
       "         3.26292776e-02,  9.32676867e-02, -7.64712989e-02,\n",
       "         1.30555496e-01,  1.16024399e-02,  2.88532693e-02,\n",
       "         1.88991383e-01, -1.19975299e-01,  1.02182321e-01,\n",
       "         2.28446275e-02, -5.92820570e-02,  1.75765574e-01,\n",
       "         2.30525985e-01,  1.90289188e-02,  9.65670776e-03,\n",
       "        -1.75568223e-01, -1.04571357e-01,  1.00492932e-01,\n",
       "         1.49767056e-01, -9.64104291e-03, -5.91125004e-02,\n",
       "        -1.39639109e-01, -1.65391222e-01,  1.24252751e-01,\n",
       "         2.32812643e-01,  8.42568800e-02, -8.04309472e-02,\n",
       "        -2.35629212e-02, -9.65854302e-02,  6.78411797e-02,\n",
       "         1.17815748e-01, -8.58614519e-02, -5.72188105e-03,\n",
       "        -1.53239518e-01, -9.83974785e-02, -7.08656460e-02,\n",
       "        -2.00072117e-02,  2.12409079e-01,  6.38984516e-02,\n",
       "        -7.54146054e-02, -6.95541501e-03, -1.88711267e-02,\n",
       "        -2.26881444e-01, -1.17579155e-01,  6.14682995e-02,\n",
       "        -9.57529768e-02, -2.68723816e-01,  1.38140498e-02,\n",
       "        -1.48776889e-01, -2.14551643e-01, -2.71532182e-02,\n",
       "         7.64086551e-04, -8.58749598e-02,  9.59005132e-02,\n",
       "         8.42652470e-02,  2.30250414e-02, -8.33435878e-02,\n",
       "         1.06013060e-01, -6.18194193e-02,  9.08680633e-03,\n",
       "         2.10714370e-01,  9.08329561e-02,  1.19526647e-01,\n",
       "         3.99766304e-03,  2.89675710e-03,  1.01296254e-03,\n",
       "        -1.15449369e-01,  5.94664156e-01,  8.78233761e-02,\n",
       "        -1.90067768e-01,  4.37146313e-02, -1.10034153e-01,\n",
       "        -2.44038671e-01,  9.18057337e-02,  9.72739712e-04,\n",
       "        -4.16261740e-02, -2.34994292e-02, -1.21468447e-01,\n",
       "         1.96778849e-02,  1.45413652e-01,  1.07298158e-01,\n",
       "         5.32302335e-02, -1.25977285e-02, -2.13557500e-02,\n",
       "         9.43812728e-02, -1.21834300e-01,  8.44525471e-02,\n",
       "        -1.57310247e-01,  8.92953873e-02, -3.63220185e-01,\n",
       "        -4.75544482e-02, -4.29949239e-02, -1.19175099e-01,\n",
       "         2.82720253e-02, -5.84695209e-03, -1.62349194e-01,\n",
       "         7.68656358e-02, -1.37244374e-01,  2.04780921e-01,\n",
       "        -4.55223322e-02, -1.18751906e-01,  1.03438869e-01,\n",
       "         5.55905253e-02, -7.00633228e-02, -2.15943158e-01,\n",
       "        -2.87905466e-02,  9.34398151e-04],\n",
       "       [ 2.56391317e-01,  1.04084378e-02,  1.93087429e-01,\n",
       "         1.89195991e-01, -1.08097708e-02,  1.45598888e-01,\n",
       "         8.39516521e-03, -5.36343269e-02, -1.54443234e-01,\n",
       "         2.24908069e-02,  3.05301510e-02,  8.12204331e-02,\n",
       "         9.67898890e-02, -3.04657966e-02,  9.58044380e-02,\n",
       "        -2.35942341e-02, -4.72652540e-02, -1.08390793e-01,\n",
       "         2.08645090e-02,  2.84858942e-01,  8.85111764e-02,\n",
       "         1.07124016e-01,  6.06636815e-02,  7.28174224e-02,\n",
       "         4.12987433e-02, -6.23816811e-02,  1.86689093e-03,\n",
       "         1.42523512e-01, -1.05154879e-01, -3.82010303e-02,\n",
       "         1.09649733e-01,  2.76021473e-02,  1.47165567e-01,\n",
       "        -5.21517806e-02, -1.15647791e-02,  4.18996364e-02,\n",
       "         1.11412421e-01, -2.54083727e-03,  9.83790159e-02,\n",
       "         8.22707415e-02,  1.17049702e-01, -1.52302161e-01,\n",
       "        -8.39411542e-02, -3.03307716e-02,  1.57194793e-01,\n",
       "         1.00994661e-01,  9.64142475e-03, -8.17999020e-02,\n",
       "        -1.09542072e-01, -4.80138622e-02, -5.68612069e-02,\n",
       "         4.07774933e-02,  1.69419631e-01,  1.95035681e-01,\n",
       "        -6.86180070e-02, -1.17889389e-01,  5.49407192e-02,\n",
       "        -1.03155419e-01,  1.06714654e-03,  1.19526565e-01,\n",
       "         1.07592307e-02,  1.34095624e-01,  9.74018797e-02,\n",
       "        -1.54516073e-02, -2.13606015e-01,  8.06542784e-02,\n",
       "         8.01256374e-02, -2.15158567e-01, -2.57234834e-02,\n",
       "        -2.86198948e-02, -6.86364099e-02,  1.50189921e-01,\n",
       "         5.13816178e-02,  1.15626096e-03,  7.53315985e-02,\n",
       "         1.25597239e-01, -5.57188168e-02, -4.47457135e-02,\n",
       "         4.30253483e-02,  6.18377030e-02,  1.82006717e-01,\n",
       "         8.66031796e-02, -8.42615739e-02, -1.44502949e-02,\n",
       "         1.87775474e-02,  2.50953455e-02,  3.58740948e-02,\n",
       "         8.93531516e-02,  4.39058952e-02,  1.28308535e-01,\n",
       "        -8.46780017e-02,  1.82489499e-01, -1.24122398e-02,\n",
       "        -8.08319524e-02,  6.56520277e-02, -7.41768852e-02,\n",
       "         7.79442936e-02, -5.16159832e-02, -8.96638855e-02,\n",
       "         1.80691138e-01,  1.82314754e-01, -3.85407470e-02,\n",
       "         1.59769192e-01,  5.98290935e-02, -5.81818335e-02,\n",
       "        -7.87499845e-02, -2.08837122e-01,  1.00372359e-02,\n",
       "        -3.49983945e-02,  9.74787027e-02, -2.67672956e-01,\n",
       "         8.32278468e-03,  5.42661399e-02,  5.31318076e-02,\n",
       "        -7.90747814e-03,  1.85750369e-02, -9.17836949e-02,\n",
       "         1.77960675e-02, -6.03543967e-02,  1.12036327e-02,\n",
       "         8.46719090e-03,  8.98348242e-02,  9.25287902e-02,\n",
       "        -1.09959774e-01,  1.25124171e-01,  6.49712682e-02,\n",
       "        -1.32842988e-01,  7.89029673e-02],\n",
       "       [ 4.52134550e-01, -5.29445335e-03,  2.95138564e-02,\n",
       "         2.62736827e-01,  2.52162248e-01, -1.55796617e-01,\n",
       "        -8.33083913e-02, -1.48524180e-01, -3.13679039e-01,\n",
       "        -5.81282657e-03, -1.11601435e-01, -1.34033978e-01,\n",
       "         7.45190773e-03, -9.31592360e-02,  4.80857156e-02,\n",
       "        -3.15705128e-02, -5.75760379e-03, -1.74759895e-01,\n",
       "         1.30771771e-01,  1.94909453e-01, -4.95943204e-02,\n",
       "        -7.64764175e-02,  1.84226707e-02,  3.40640657e-02,\n",
       "        -1.51789710e-02,  2.44688336e-02,  5.97060891e-04,\n",
       "         1.67791788e-02, -1.70886397e-01, -9.93590876e-02,\n",
       "        -1.93963870e-01,  4.28060582e-03,  1.44674495e-01,\n",
       "        -1.96834683e-01,  1.55188963e-01,  2.35225372e-02,\n",
       "        -1.93755731e-01, -4.93526906e-02,  2.02284902e-01,\n",
       "         2.32904121e-01, -6.38984367e-02, -1.67159140e-01,\n",
       "        -8.06071684e-02, -1.78892866e-01,  1.24232948e-01,\n",
       "         1.48841619e-01, -4.04960215e-02, -1.05219729e-01,\n",
       "        -4.81739193e-02,  3.61671112e-02, -8.24260861e-02,\n",
       "         1.03493519e-01, -5.46263680e-02,  1.13606587e-01,\n",
       "        -1.44975990e-01, -2.02557042e-01, -2.49362327e-02,\n",
       "        -2.22035095e-01,  3.19670327e-02,  7.90705830e-02,\n",
       "        -2.50329059e-02,  2.42385849e-01,  8.07029828e-02,\n",
       "        -9.17324200e-02, -6.30227923e-02,  1.62440091e-01,\n",
       "         9.45178941e-02, -3.91176753e-02, -2.57022306e-02,\n",
       "        -3.77486572e-02, -1.82821393e-01,  1.93361610e-01,\n",
       "         3.59833278e-02, -1.15961865e-01,  9.28260852e-03,\n",
       "         8.87204036e-02, -4.26153094e-02, -1.93308756e-01,\n",
       "         7.50354603e-02, -6.29742891e-02,  2.14945138e-01,\n",
       "         2.76724435e-02, -3.78942974e-02, -1.52389050e-01,\n",
       "        -6.94958791e-02,  8.14762861e-02, -1.32254809e-01,\n",
       "         1.35713788e-02,  5.17274976e-01, -4.05215919e-02,\n",
       "        -1.97256461e-01,  6.00447319e-02,  5.80043830e-02,\n",
       "        -1.66122675e-01,  1.30342588e-01,  5.56229986e-02,\n",
       "        -9.50153917e-02, -6.44592270e-02, -3.29186708e-01,\n",
       "         6.87694326e-02,  1.09234929e-01,  1.38048306e-01,\n",
       "         1.95030853e-01, -6.74392954e-02, -3.00181396e-02,\n",
       "        -9.34729129e-02, -3.06908768e-02,  1.29362345e-01,\n",
       "        -1.91656932e-01,  1.10758319e-01, -4.55144018e-01,\n",
       "        -5.64635061e-02, -8.98777172e-02, -2.14716151e-01,\n",
       "        -1.06982097e-01, -4.02070619e-02, -3.24770994e-02,\n",
       "         8.78347978e-02, -2.99487919e-01,  8.44677463e-02,\n",
       "        -4.66716923e-02,  7.02228397e-02,  3.89887318e-02,\n",
       "         1.20948888e-01,  2.55592912e-01, -1.13746792e-01,\n",
       "        -1.37379616e-01,  2.81750858e-02],\n",
       "       [ 6.22674823e-01,  1.00250483e-01,  7.57317757e-03,\n",
       "         9.76786539e-02, -1.21261412e-02,  5.02556488e-02,\n",
       "        -4.70215008e-02, -1.27638102e-01, -1.18818372e-01,\n",
       "         7.28872865e-02,  3.14558782e-02,  6.68873563e-02,\n",
       "        -2.43326579e-03, -8.81048590e-02, -1.89422201e-02,\n",
       "        -1.62832767e-01, -5.17561957e-02, -1.07286181e-02,\n",
       "        -9.98059958e-02,  4.53412324e-01,  5.47106639e-02,\n",
       "         3.58776376e-02,  1.39915408e-03,  5.92471920e-02,\n",
       "         9.89110842e-02,  5.39284050e-02, -6.91096559e-02,\n",
       "         3.00763529e-02, -1.57566518e-01,  1.21509232e-01,\n",
       "         1.40514389e-01, -3.96777354e-02,  6.94171563e-02,\n",
       "        -2.07493324e-02, -9.42897797e-02,  5.05543947e-02,\n",
       "        -3.03056352e-02, -2.70525366e-02, -3.32568809e-02,\n",
       "         6.38592616e-02,  1.13981672e-01, -1.64757177e-01,\n",
       "        -7.18250424e-02, -1.77902803e-02, -1.82313006e-02,\n",
       "         1.09215900e-01,  6.51093712e-03, -1.79240629e-01,\n",
       "        -2.05570653e-01,  1.27154682e-02, -7.33933672e-02,\n",
       "         9.17607248e-02,  1.52924925e-01,  7.36561418e-02,\n",
       "        -8.76445249e-02,  1.07784435e-01,  5.99157214e-02,\n",
       "        -5.65376580e-02, -3.23640008e-04,  1.43551916e-01,\n",
       "         6.32977560e-02,  1.13122180e-01, -5.75116426e-02,\n",
       "        -4.56382520e-02, -1.29984185e-01, -2.06344458e-03,\n",
       "        -6.52884766e-02, -3.10155064e-01, -9.38412622e-02,\n",
       "         6.39795605e-03, -4.33407091e-02,  8.65935087e-02,\n",
       "        -7.95920193e-03, -9.33224931e-02,  1.51901826e-01,\n",
       "        -1.37593895e-01, -2.61061251e-01, -3.39554101e-02,\n",
       "         1.37075391e-02, -5.68551309e-02,  7.31915981e-02,\n",
       "         1.64634362e-01,  1.19589958e-02,  1.24598943e-01,\n",
       "         4.22471389e-02, -2.60840654e-02, -1.91244222e-02,\n",
       "         4.72878367e-02,  5.03152847e-01,  2.66002506e-01,\n",
       "        -1.70589909e-01,  7.66468570e-02,  7.57535249e-02,\n",
       "        -7.07639530e-02, -3.29299793e-02,  3.04571465e-02,\n",
       "         1.06796147e-02, -1.11898050e-01, -9.96344462e-02,\n",
       "         6.59293607e-02,  1.41837910e-01,  2.00370490e-03,\n",
       "        -8.31104629e-03,  8.58155414e-02,  5.89671023e-02,\n",
       "        -2.41717286e-02, -1.99772805e-01, -3.74799296e-02,\n",
       "        -1.75030738e-01,  7.67340586e-02, -2.91215211e-01,\n",
       "        -5.08489534e-02,  1.29462868e-01, -4.24716324e-02,\n",
       "         5.39170876e-02, -5.24121858e-02, -1.31669417e-01,\n",
       "         6.84974417e-02, -7.45027959e-02,  1.39548287e-01,\n",
       "         9.72736403e-02, -4.46114615e-02, -5.08588701e-02,\n",
       "        -1.08166181e-01,  8.09003562e-02,  2.22466700e-02,\n",
       "        -6.19275682e-02,  3.59582864e-02],\n",
       "       [ 2.49615520e-01, -1.47321433e-01,  2.42271200e-02,\n",
       "         2.04302222e-02,  1.53095648e-01,  6.12013973e-02,\n",
       "        -1.82217613e-01, -7.56077543e-02, -3.77568183e-04,\n",
       "        -7.64185190e-03, -4.51893993e-02, -5.83954388e-04,\n",
       "        -5.24381176e-02, -1.41820103e-01, -2.49693710e-02,\n",
       "         5.88124385e-03, -6.80975243e-02, -1.14043411e-02,\n",
       "        -1.36477053e-01, -1.18781915e-02, -3.77312349e-03,\n",
       "         1.03830814e-01, -6.59616068e-02,  1.69256013e-02,\n",
       "        -3.82180437e-02,  5.35876937e-02,  5.71425408e-02,\n",
       "        -5.04979193e-02, -1.34534389e-01, -6.81776777e-02,\n",
       "         1.21991962e-01, -1.28450781e-01,  1.32165447e-01,\n",
       "         1.73288044e-02, -6.04551286e-03, -1.05423279e-01,\n",
       "         8.89861658e-02, -1.05403319e-01,  1.79033615e-02,\n",
       "         1.37743160e-01, -1.97868366e-02, -3.33565772e-02,\n",
       "        -5.47080785e-02, -1.45057440e-01,  2.05844745e-01,\n",
       "         1.08114406e-01,  4.23301831e-02, -1.55732825e-01,\n",
       "        -2.23408192e-01, -1.71062276e-01,  1.33848423e-02,\n",
       "         8.77822265e-02, -6.77496893e-04,  6.09808154e-02,\n",
       "        -5.59739694e-02, -2.34525278e-02, -9.33634639e-02,\n",
       "        -2.44162958e-02,  8.53352770e-02, -7.35548884e-02,\n",
       "        -2.42761746e-02,  8.68679360e-02, -5.33482879e-02,\n",
       "         6.58220574e-02, -6.56172261e-02, -1.12850972e-01,\n",
       "        -3.96310389e-02, -8.60085636e-02, -1.16174202e-02,\n",
       "        -2.26707570e-02, -2.14514025e-02, -2.66776141e-02,\n",
       "        -1.26232747e-02, -8.84903446e-02,  1.20819911e-01,\n",
       "        -4.83580120e-02, -1.96726263e-01, -2.73738485e-02,\n",
       "        -2.16114316e-02,  7.78773800e-02,  3.54831596e-03,\n",
       "         2.43526399e-02, -7.92798996e-02,  1.55726254e-01,\n",
       "        -5.43418303e-02, -9.25542489e-02,  1.07187293e-01,\n",
       "         8.52273479e-02,  3.14577341e-01,  3.40552218e-02,\n",
       "        -1.54140875e-01, -8.67419690e-02, -8.17644447e-02,\n",
       "        -1.89272955e-01, -6.62048906e-02,  9.56602767e-02,\n",
       "         9.95677933e-02,  4.61086221e-02, -1.67776365e-02,\n",
       "        -8.99081305e-02,  4.73446324e-02, -6.70295581e-03,\n",
       "         9.86140892e-02,  1.23186074e-01,  1.63740203e-01,\n",
       "         1.39627069e-01, -4.76862341e-02, -2.26955980e-01,\n",
       "        -1.48841947e-01,  1.38237122e-02, -1.37766868e-01,\n",
       "        -1.09409876e-01, -1.86367836e-02,  1.01510435e-01,\n",
       "         5.53108938e-02, -1.35068655e-01, -1.88439488e-01,\n",
       "         1.33823842e-01, -1.37551837e-02, -1.28548854e-04,\n",
       "         1.32960498e-01,  4.94608143e-03, -1.41066154e-02,\n",
       "         1.57424435e-01,  1.57887518e-01,  1.73398525e-01,\n",
       "        -1.41026840e-01, -3.56639409e-03]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 3, 5, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = create_model(x1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 71,189\n",
      "Trainable params: 71,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1068 samples, validate on 268 samples\n",
      "Epoch 1/1000\n",
      "1068/1068 [==============================] - 0s 405us/step - loss: 3.5358 - mean_squared_error: 3.5358 - val_loss: 2.1366 - val_mean_squared_error: 2.1366\n",
      "Epoch 2/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 2.5506 - mean_squared_error: 2.5506 - val_loss: 1.7840 - val_mean_squared_error: 1.7840\n",
      "Epoch 3/1000\n",
      " 640/1068 [================>.............] - ETA: 0s - loss: 2.1129 - mean_squared_error: 2.1129"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SODIQ-PC\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `acc` which is not available. Available metrics are: mean_squared_error,loss,val_mean_squared_error,val_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 100us/step - loss: 2.1129 - mean_squared_error: 2.1129 - val_loss: 1.5709 - val_mean_squared_error: 1.5709\n",
      "Epoch 4/1000\n",
      "1068/1068 [==============================] - 0s 118us/step - loss: 1.9543 - mean_squared_error: 1.9543 - val_loss: 1.3190 - val_mean_squared_error: 1.3190\n",
      "Epoch 5/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 2.0189 - mean_squared_error: 2.0189 - val_loss: 1.2045 - val_mean_squared_error: 1.2045\n",
      "Epoch 6/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 1.7777 - mean_squared_error: 1.7777 - val_loss: 1.2025 - val_mean_squared_error: 1.2025\n",
      "Epoch 7/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 1.8183 - mean_squared_error: 1.8183 - val_loss: 1.2874 - val_mean_squared_error: 1.2874\n",
      "Epoch 8/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 1.7307 - mean_squared_error: 1.7307 - val_loss: 1.1447 - val_mean_squared_error: 1.1447\n",
      "Epoch 9/1000\n",
      "1068/1068 [==============================] - 0s 112us/step - loss: 1.6032 - mean_squared_error: 1.6032 - val_loss: 0.9983 - val_mean_squared_error: 0.9983\n",
      "Epoch 10/1000\n",
      "1068/1068 [==============================] - 0s 120us/step - loss: 1.5923 - mean_squared_error: 1.5923 - val_loss: 0.9790 - val_mean_squared_error: 0.9790\n",
      "Epoch 11/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 1.5743 - mean_squared_error: 1.5743 - val_loss: 1.0955 - val_mean_squared_error: 1.0955\n",
      "Epoch 12/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 1.4746 - mean_squared_error: 1.4746 - val_loss: 0.9905 - val_mean_squared_error: 0.9905\n",
      "Epoch 13/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 1.4830 - mean_squared_error: 1.4830 - val_loss: 0.9992 - val_mean_squared_error: 0.9992\n",
      "Epoch 14/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 1.3531 - mean_squared_error: 1.3531 - val_loss: 1.0546 - val_mean_squared_error: 1.0546\n",
      "Epoch 15/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 1.3139 - mean_squared_error: 1.3139 - val_loss: 1.1028 - val_mean_squared_error: 1.1028\n",
      "Epoch 16/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 1.2643 - mean_squared_error: 1.2643 - val_loss: 1.0242 - val_mean_squared_error: 1.0242\n",
      "Epoch 17/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 1.2528 - mean_squared_error: 1.2528 - val_loss: 0.9352 - val_mean_squared_error: 0.9352\n",
      "Epoch 18/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 1.2990 - mean_squared_error: 1.2990 - val_loss: 0.9065 - val_mean_squared_error: 0.9065\n",
      "Epoch 19/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 1.1929 - mean_squared_error: 1.1929 - val_loss: 1.0905 - val_mean_squared_error: 1.0905\n",
      "Epoch 20/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 1.1885 - mean_squared_error: 1.1885 - val_loss: 0.9172 - val_mean_squared_error: 0.9172\n",
      "Epoch 21/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 1.2329 - mean_squared_error: 1.2329 - val_loss: 1.0333 - val_mean_squared_error: 1.0333\n",
      "Epoch 22/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 1.1286 - mean_squared_error: 1.1286 - val_loss: 0.9052 - val_mean_squared_error: 0.9052\n",
      "Epoch 23/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 1.0234 - mean_squared_error: 1.0234 - val_loss: 0.8327 - val_mean_squared_error: 0.8327\n",
      "Epoch 24/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 1.0525 - mean_squared_error: 1.0525 - val_loss: 0.8252 - val_mean_squared_error: 0.8252\n",
      "Epoch 25/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.9604 - mean_squared_error: 0.9604 - val_loss: 0.8215 - val_mean_squared_error: 0.8215\n",
      "Epoch 26/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 1.0283 - mean_squared_error: 1.0283 - val_loss: 0.8397 - val_mean_squared_error: 0.8397\n",
      "Epoch 27/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.9664 - mean_squared_error: 0.9664 - val_loss: 0.8206 - val_mean_squared_error: 0.8206\n",
      "Epoch 28/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.9530 - mean_squared_error: 0.9530 - val_loss: 0.9295 - val_mean_squared_error: 0.9295\n",
      "Epoch 29/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.8561 - mean_squared_error: 0.8561 - val_loss: 0.9414 - val_mean_squared_error: 0.9414\n",
      "Epoch 30/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.9048 - mean_squared_error: 0.9048 - val_loss: 0.8082 - val_mean_squared_error: 0.8082\n",
      "Epoch 31/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.8925 - mean_squared_error: 0.8925 - val_loss: 0.8434 - val_mean_squared_error: 0.8434\n",
      "Epoch 32/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.9670 - mean_squared_error: 0.9670 - val_loss: 0.7954 - val_mean_squared_error: 0.7954\n",
      "Epoch 33/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.9236 - mean_squared_error: 0.9236 - val_loss: 0.8798 - val_mean_squared_error: 0.8798\n",
      "Epoch 34/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.8197 - mean_squared_error: 0.8197 - val_loss: 0.8300 - val_mean_squared_error: 0.8300\n",
      "Epoch 35/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.8531 - mean_squared_error: 0.8531 - val_loss: 0.7931 - val_mean_squared_error: 0.7931\n",
      "Epoch 36/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.8163 - mean_squared_error: 0.8163 - val_loss: 0.8151 - val_mean_squared_error: 0.8151\n",
      "Epoch 37/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.7482 - mean_squared_error: 0.7482 - val_loss: 0.8757 - val_mean_squared_error: 0.8757\n",
      "Epoch 38/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.7983 - mean_squared_error: 0.7983 - val_loss: 0.7927 - val_mean_squared_error: 0.7927\n",
      "Epoch 39/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.7504 - mean_squared_error: 0.7504 - val_loss: 0.9811 - val_mean_squared_error: 0.9811\n",
      "Epoch 40/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.8229 - mean_squared_error: 0.8229 - val_loss: 0.9014 - val_mean_squared_error: 0.9014\n",
      "Epoch 41/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.7157 - mean_squared_error: 0.7157 - val_loss: 0.7987 - val_mean_squared_error: 0.7987\n",
      "Epoch 42/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.7583 - mean_squared_error: 0.7583 - val_loss: 0.7765 - val_mean_squared_error: 0.7765\n",
      "Epoch 43/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.6947 - mean_squared_error: 0.6947 - val_loss: 0.8079 - val_mean_squared_error: 0.8079\n",
      "Epoch 44/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.7294 - mean_squared_error: 0.7294 - val_loss: 0.8534 - val_mean_squared_error: 0.8534\n",
      "Epoch 45/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.6748 - mean_squared_error: 0.6748 - val_loss: 0.8259 - val_mean_squared_error: 0.8259\n",
      "Epoch 46/1000\n",
      "1068/1068 [==============================] - 0s 120us/step - loss: 0.6093 - mean_squared_error: 0.6093 - val_loss: 0.8526 - val_mean_squared_error: 0.8526\n",
      "Epoch 47/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.6847 - mean_squared_error: 0.6847 - val_loss: 0.8500 - val_mean_squared_error: 0.8500\n",
      "Epoch 48/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.6638 - mean_squared_error: 0.6638 - val_loss: 0.8490 - val_mean_squared_error: 0.8490\n",
      "Epoch 49/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.6025 - mean_squared_error: 0.6025 - val_loss: 0.8527 - val_mean_squared_error: 0.8527\n",
      "Epoch 50/1000\n",
      "1068/1068 [==============================] - 0s 122us/step - loss: 0.5764 - mean_squared_error: 0.5764 - val_loss: 0.8941 - val_mean_squared_error: 0.8941\n",
      "Epoch 51/1000\n",
      "1068/1068 [==============================] - 0s 112us/step - loss: 0.5841 - mean_squared_error: 0.5841 - val_loss: 0.8792 - val_mean_squared_error: 0.8792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.6389 - mean_squared_error: 0.6389 - val_loss: 0.8376 - val_mean_squared_error: 0.8376\n",
      "Epoch 53/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.6045 - mean_squared_error: 0.6045 - val_loss: 0.9070 - val_mean_squared_error: 0.9070\n",
      "Epoch 54/1000\n",
      "1068/1068 [==============================] - 0s 115us/step - loss: 0.6010 - mean_squared_error: 0.6010 - val_loss: 0.8060 - val_mean_squared_error: 0.8060\n",
      "Epoch 55/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.6225 - mean_squared_error: 0.6225 - val_loss: 0.8049 - val_mean_squared_error: 0.8049\n",
      "Epoch 56/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.5578 - mean_squared_error: 0.5578 - val_loss: 0.8227 - val_mean_squared_error: 0.8227\n",
      "Epoch 57/1000\n",
      "1068/1068 [==============================] - 0s 132us/step - loss: 0.4974 - mean_squared_error: 0.4974 - val_loss: 0.8118 - val_mean_squared_error: 0.8118\n",
      "Epoch 58/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.5880 - mean_squared_error: 0.5880 - val_loss: 0.9498 - val_mean_squared_error: 0.9498\n",
      "Epoch 59/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.5704 - mean_squared_error: 0.5704 - val_loss: 0.8132 - val_mean_squared_error: 0.8132\n",
      "Epoch 60/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.6065 - mean_squared_error: 0.6065 - val_loss: 0.8913 - val_mean_squared_error: 0.8913\n",
      "Epoch 61/1000\n",
      "1068/1068 [==============================] - 0s 114us/step - loss: 0.5512 - mean_squared_error: 0.5512 - val_loss: 0.7920 - val_mean_squared_error: 0.7920\n",
      "Epoch 62/1000\n",
      "1068/1068 [==============================] - 0s 124us/step - loss: 0.4846 - mean_squared_error: 0.4846 - val_loss: 0.7600 - val_mean_squared_error: 0.7600\n",
      "Epoch 63/1000\n",
      "1068/1068 [==============================] - 0s 116us/step - loss: 0.5154 - mean_squared_error: 0.5154 - val_loss: 0.8433 - val_mean_squared_error: 0.8433\n",
      "Epoch 64/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.5200 - mean_squared_error: 0.5200 - val_loss: 0.8019 - val_mean_squared_error: 0.8019\n",
      "Epoch 65/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.5171 - mean_squared_error: 0.5171 - val_loss: 0.8314 - val_mean_squared_error: 0.8314\n",
      "Epoch 66/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.5056 - mean_squared_error: 0.5056 - val_loss: 0.8916 - val_mean_squared_error: 0.8916\n",
      "Epoch 67/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.4620 - mean_squared_error: 0.4620 - val_loss: 0.9258 - val_mean_squared_error: 0.9258\n",
      "Epoch 68/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.4895 - mean_squared_error: 0.4895 - val_loss: 0.8228 - val_mean_squared_error: 0.8228\n",
      "Epoch 69/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.5092 - mean_squared_error: 0.5092 - val_loss: 0.8145 - val_mean_squared_error: 0.8145\n",
      "Epoch 70/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4906 - mean_squared_error: 0.4906 - val_loss: 0.7932 - val_mean_squared_error: 0.7932\n",
      "Epoch 71/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4831 - mean_squared_error: 0.4831 - val_loss: 0.8258 - val_mean_squared_error: 0.8258\n",
      "Epoch 72/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.4419 - mean_squared_error: 0.4419 - val_loss: 0.7973 - val_mean_squared_error: 0.7973\n",
      "Epoch 73/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.4420 - mean_squared_error: 0.4420 - val_loss: 0.8343 - val_mean_squared_error: 0.8343\n",
      "Epoch 74/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.4884 - mean_squared_error: 0.4884 - val_loss: 0.7942 - val_mean_squared_error: 0.7942\n",
      "Epoch 75/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.4700 - mean_squared_error: 0.4700 - val_loss: 0.7880 - val_mean_squared_error: 0.7880\n",
      "Epoch 76/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.4588 - mean_squared_error: 0.4588 - val_loss: 0.8359 - val_mean_squared_error: 0.8359\n",
      "Epoch 77/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4430 - mean_squared_error: 0.4430 - val_loss: 0.8035 - val_mean_squared_error: 0.8035\n",
      "Epoch 78/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.4630 - mean_squared_error: 0.4630 - val_loss: 0.7893 - val_mean_squared_error: 0.7893\n",
      "Epoch 79/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.4435 - mean_squared_error: 0.4435 - val_loss: 0.8183 - val_mean_squared_error: 0.8183\n",
      "Epoch 80/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4626 - mean_squared_error: 0.4626 - val_loss: 0.9215 - val_mean_squared_error: 0.9215\n",
      "Epoch 81/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.4653 - mean_squared_error: 0.4653 - val_loss: 0.8526 - val_mean_squared_error: 0.8526\n",
      "Epoch 82/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.4626 - mean_squared_error: 0.4626 - val_loss: 0.8225 - val_mean_squared_error: 0.8225\n",
      "Epoch 83/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4311 - mean_squared_error: 0.4311 - val_loss: 0.8195 - val_mean_squared_error: 0.8195\n",
      "Epoch 84/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4454 - mean_squared_error: 0.4454 - val_loss: 0.7784 - val_mean_squared_error: 0.7784\n",
      "Epoch 85/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4460 - mean_squared_error: 0.4460 - val_loss: 0.7932 - val_mean_squared_error: 0.7932\n",
      "Epoch 86/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4173 - mean_squared_error: 0.4173 - val_loss: 0.7875 - val_mean_squared_error: 0.7875\n",
      "Epoch 87/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4769 - mean_squared_error: 0.4769 - val_loss: 0.8200 - val_mean_squared_error: 0.8200\n",
      "Epoch 88/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.4359 - mean_squared_error: 0.4359 - val_loss: 0.8542 - val_mean_squared_error: 0.8542\n",
      "Epoch 89/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3901 - mean_squared_error: 0.3901 - val_loss: 0.7816 - val_mean_squared_error: 0.7816\n",
      "Epoch 90/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.4184 - mean_squared_error: 0.4184 - val_loss: 0.8141 - val_mean_squared_error: 0.8141\n",
      "Epoch 91/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.4348 - mean_squared_error: 0.4348 - val_loss: 0.8108 - val_mean_squared_error: 0.8108\n",
      "Epoch 92/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4122 - mean_squared_error: 0.4122 - val_loss: 0.7780 - val_mean_squared_error: 0.7780\n",
      "Epoch 93/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.4263 - mean_squared_error: 0.4263 - val_loss: 0.7783 - val_mean_squared_error: 0.7783\n",
      "Epoch 94/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.4484 - mean_squared_error: 0.4484 - val_loss: 0.7859 - val_mean_squared_error: 0.7859\n",
      "Epoch 95/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.4423 - mean_squared_error: 0.4423 - val_loss: 0.8346 - val_mean_squared_error: 0.8346\n",
      "Epoch 96/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4426 - mean_squared_error: 0.4426 - val_loss: 0.8078 - val_mean_squared_error: 0.8078\n",
      "Epoch 97/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.4609 - mean_squared_error: 0.4609 - val_loss: 0.8863 - val_mean_squared_error: 0.8863\n",
      "Epoch 98/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3765 - mean_squared_error: 0.3765 - val_loss: 0.7865 - val_mean_squared_error: 0.7865\n",
      "Epoch 99/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4063 - mean_squared_error: 0.4063 - val_loss: 0.8064 - val_mean_squared_error: 0.8064\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.4355 - mean_squared_error: 0.4355 - val_loss: 0.7947 - val_mean_squared_error: 0.7947\n",
      "Epoch 101/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3962 - mean_squared_error: 0.3962 - val_loss: 0.8146 - val_mean_squared_error: 0.8146\n",
      "Epoch 102/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.4336 - mean_squared_error: 0.4336 - val_loss: 0.8375 - val_mean_squared_error: 0.8375\n",
      "Epoch 103/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3952 - mean_squared_error: 0.3952 - val_loss: 0.8008 - val_mean_squared_error: 0.8008\n",
      "Epoch 104/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.4435 - mean_squared_error: 0.4435 - val_loss: 0.7884 - val_mean_squared_error: 0.7884\n",
      "Epoch 105/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.4517 - mean_squared_error: 0.4517 - val_loss: 0.7818 - val_mean_squared_error: 0.7818\n",
      "Epoch 106/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.4483 - mean_squared_error: 0.4483 - val_loss: 0.8445 - val_mean_squared_error: 0.8445\n",
      "Epoch 107/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.4228 - mean_squared_error: 0.4228 - val_loss: 0.7731 - val_mean_squared_error: 0.7731\n",
      "Epoch 108/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3993 - mean_squared_error: 0.3993 - val_loss: 0.7944 - val_mean_squared_error: 0.7944\n",
      "Epoch 109/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3895 - mean_squared_error: 0.3895 - val_loss: 0.7814 - val_mean_squared_error: 0.7814\n",
      "Epoch 110/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.4159 - mean_squared_error: 0.4159 - val_loss: 0.8111 - val_mean_squared_error: 0.8111\n",
      "Epoch 111/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3958 - mean_squared_error: 0.3958 - val_loss: 0.8061 - val_mean_squared_error: 0.8061\n",
      "Epoch 112/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3663 - mean_squared_error: 0.3663 - val_loss: 0.8094 - val_mean_squared_error: 0.8094\n",
      "Epoch 113/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.4351 - mean_squared_error: 0.4351 - val_loss: 0.7847 - val_mean_squared_error: 0.7847\n",
      "Epoch 114/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3851 - mean_squared_error: 0.3851 - val_loss: 0.7815 - val_mean_squared_error: 0.7815\n",
      "Epoch 115/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3827 - mean_squared_error: 0.3827 - val_loss: 0.8073 - val_mean_squared_error: 0.8073\n",
      "Epoch 116/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4664 - mean_squared_error: 0.4664 - val_loss: 0.7823 - val_mean_squared_error: 0.7823\n",
      "Epoch 117/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.7675 - val_mean_squared_error: 0.7675\n",
      "Epoch 118/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.4153 - mean_squared_error: 0.4153 - val_loss: 0.8089 - val_mean_squared_error: 0.8089\n",
      "Epoch 119/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3851 - mean_squared_error: 0.3851 - val_loss: 0.8074 - val_mean_squared_error: 0.8074\n",
      "Epoch 120/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3940 - mean_squared_error: 0.3940 - val_loss: 0.7799 - val_mean_squared_error: 0.7799\n",
      "Epoch 121/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3787 - mean_squared_error: 0.3787 - val_loss: 0.8326 - val_mean_squared_error: 0.8326\n",
      "Epoch 122/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3642 - mean_squared_error: 0.3642 - val_loss: 0.8013 - val_mean_squared_error: 0.8013\n",
      "Epoch 123/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.4096 - mean_squared_error: 0.4096 - val_loss: 0.7775 - val_mean_squared_error: 0.7775\n",
      "Epoch 124/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3783 - mean_squared_error: 0.3783 - val_loss: 0.7952 - val_mean_squared_error: 0.7952\n",
      "Epoch 125/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3880 - mean_squared_error: 0.3880 - val_loss: 0.7664 - val_mean_squared_error: 0.7664\n",
      "Epoch 126/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3666 - mean_squared_error: 0.3666 - val_loss: 0.8045 - val_mean_squared_error: 0.8045\n",
      "Epoch 127/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3587 - mean_squared_error: 0.3587 - val_loss: 0.7945 - val_mean_squared_error: 0.7945\n",
      "Epoch 128/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3815 - mean_squared_error: 0.3815 - val_loss: 0.7990 - val_mean_squared_error: 0.7990\n",
      "Epoch 129/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3802 - mean_squared_error: 0.3802 - val_loss: 0.8186 - val_mean_squared_error: 0.8186\n",
      "Epoch 130/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3999 - mean_squared_error: 0.3999 - val_loss: 0.7928 - val_mean_squared_error: 0.7928\n",
      "Epoch 131/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3643 - mean_squared_error: 0.3643 - val_loss: 0.7895 - val_mean_squared_error: 0.7895\n",
      "Epoch 132/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3725 - mean_squared_error: 0.3725 - val_loss: 0.7706 - val_mean_squared_error: 0.7706\n",
      "Epoch 133/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3979 - mean_squared_error: 0.3979 - val_loss: 0.7659 - val_mean_squared_error: 0.7659\n",
      "Epoch 134/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3474 - mean_squared_error: 0.3474 - val_loss: 0.7761 - val_mean_squared_error: 0.7761\n",
      "Epoch 135/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3962 - mean_squared_error: 0.3962 - val_loss: 0.7630 - val_mean_squared_error: 0.7630\n",
      "Epoch 136/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3986 - mean_squared_error: 0.3986 - val_loss: 0.8076 - val_mean_squared_error: 0.8076\n",
      "Epoch 137/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.4181 - mean_squared_error: 0.4181 - val_loss: 0.8261 - val_mean_squared_error: 0.8261\n",
      "Epoch 138/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3890 - mean_squared_error: 0.3890 - val_loss: 0.7669 - val_mean_squared_error: 0.7669\n",
      "Epoch 139/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3964 - mean_squared_error: 0.3964 - val_loss: 0.7641 - val_mean_squared_error: 0.7641\n",
      "Epoch 140/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3451 - mean_squared_error: 0.3451 - val_loss: 0.7686 - val_mean_squared_error: 0.7686\n",
      "Epoch 141/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3837 - mean_squared_error: 0.3837 - val_loss: 0.7727 - val_mean_squared_error: 0.7727\n",
      "Epoch 142/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3934 - mean_squared_error: 0.3934 - val_loss: 0.7778 - val_mean_squared_error: 0.7778\n",
      "Epoch 143/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.4324 - mean_squared_error: 0.4324 - val_loss: 0.7702 - val_mean_squared_error: 0.7702\n",
      "Epoch 144/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3938 - mean_squared_error: 0.3938 - val_loss: 0.7840 - val_mean_squared_error: 0.7840\n",
      "Epoch 145/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3528 - mean_squared_error: 0.3528 - val_loss: 0.8008 - val_mean_squared_error: 0.8008\n",
      "Epoch 146/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.4350 - mean_squared_error: 0.4350 - val_loss: 0.7719 - val_mean_squared_error: 0.7719\n",
      "Epoch 147/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3915 - mean_squared_error: 0.3915 - val_loss: 0.7674 - val_mean_squared_error: 0.7674\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 118us/step - loss: 0.3634 - mean_squared_error: 0.3634 - val_loss: 0.7752 - val_mean_squared_error: 0.7752\n",
      "Epoch 149/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3739 - mean_squared_error: 0.3739 - val_loss: 0.7725 - val_mean_squared_error: 0.7725\n",
      "Epoch 150/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3348 - mean_squared_error: 0.3348 - val_loss: 0.7965 - val_mean_squared_error: 0.7965\n",
      "Epoch 151/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3637 - mean_squared_error: 0.3637 - val_loss: 0.7415 - val_mean_squared_error: 0.7415\n",
      "Epoch 152/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3389 - mean_squared_error: 0.3389 - val_loss: 0.7669 - val_mean_squared_error: 0.7669\n",
      "Epoch 153/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3680 - mean_squared_error: 0.3680 - val_loss: 0.7828 - val_mean_squared_error: 0.7828\n",
      "Epoch 154/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3760 - mean_squared_error: 0.3760 - val_loss: 0.7621 - val_mean_squared_error: 0.7621\n",
      "Epoch 155/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3803 - mean_squared_error: 0.3803 - val_loss: 0.7607 - val_mean_squared_error: 0.7607\n",
      "Epoch 156/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.4018 - mean_squared_error: 0.4018 - val_loss: 0.8201 - val_mean_squared_error: 0.8201\n",
      "Epoch 157/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3898 - mean_squared_error: 0.3898 - val_loss: 0.8070 - val_mean_squared_error: 0.8070\n",
      "Epoch 158/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3965 - mean_squared_error: 0.3965 - val_loss: 0.7985 - val_mean_squared_error: 0.7985\n",
      "Epoch 159/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.4173 - mean_squared_error: 0.4173 - val_loss: 0.7872 - val_mean_squared_error: 0.7872\n",
      "Epoch 160/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3887 - mean_squared_error: 0.3887 - val_loss: 0.7919 - val_mean_squared_error: 0.7919\n",
      "Epoch 161/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3864 - mean_squared_error: 0.3864 - val_loss: 0.7756 - val_mean_squared_error: 0.7756\n",
      "Epoch 162/1000\n",
      "1068/1068 [==============================] - 0s 114us/step - loss: 0.3866 - mean_squared_error: 0.3866 - val_loss: 0.7830 - val_mean_squared_error: 0.7830\n",
      "Epoch 163/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3600 - mean_squared_error: 0.3600 - val_loss: 0.7639 - val_mean_squared_error: 0.7639\n",
      "Epoch 164/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3884 - mean_squared_error: 0.3884 - val_loss: 0.8029 - val_mean_squared_error: 0.8029\n",
      "Epoch 165/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.4152 - mean_squared_error: 0.4152 - val_loss: 0.8003 - val_mean_squared_error: 0.8003\n",
      "Epoch 166/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3633 - mean_squared_error: 0.3633 - val_loss: 0.7842 - val_mean_squared_error: 0.7842\n",
      "Epoch 167/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.8076 - val_mean_squared_error: 0.8076\n",
      "Epoch 168/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3362 - mean_squared_error: 0.3362 - val_loss: 0.7772 - val_mean_squared_error: 0.7772\n",
      "Epoch 169/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3931 - mean_squared_error: 0.3931 - val_loss: 0.7829 - val_mean_squared_error: 0.7829\n",
      "Epoch 170/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.7742 - val_mean_squared_error: 0.7742\n",
      "Epoch 171/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3671 - mean_squared_error: 0.3671 - val_loss: 0.7859 - val_mean_squared_error: 0.7859\n",
      "Epoch 172/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3672 - mean_squared_error: 0.3672 - val_loss: 0.7873 - val_mean_squared_error: 0.7873\n",
      "Epoch 173/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3741 - mean_squared_error: 0.3741 - val_loss: 0.7785 - val_mean_squared_error: 0.7785\n",
      "Epoch 174/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3693 - mean_squared_error: 0.3693 - val_loss: 0.7965 - val_mean_squared_error: 0.7965\n",
      "Epoch 175/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.4213 - mean_squared_error: 0.4213 - val_loss: 0.7967 - val_mean_squared_error: 0.7967\n",
      "Epoch 176/1000\n",
      "1068/1068 [==============================] - 0s 115us/step - loss: 0.3979 - mean_squared_error: 0.3979 - val_loss: 0.8045 - val_mean_squared_error: 0.8045\n",
      "Epoch 177/1000\n",
      "1068/1068 [==============================] - 0s 113us/step - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 0.7713 - val_mean_squared_error: 0.7713\n",
      "Epoch 178/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.8113 - val_mean_squared_error: 0.8113\n",
      "Epoch 179/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3526 - mean_squared_error: 0.3526 - val_loss: 0.7787 - val_mean_squared_error: 0.7787\n",
      "Epoch 180/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3597 - mean_squared_error: 0.3597 - val_loss: 0.7849 - val_mean_squared_error: 0.7849\n",
      "Epoch 181/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3776 - mean_squared_error: 0.3776 - val_loss: 0.7649 - val_mean_squared_error: 0.7649\n",
      "Epoch 182/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3583 - mean_squared_error: 0.3583 - val_loss: 0.7683 - val_mean_squared_error: 0.7683\n",
      "Epoch 183/1000\n",
      "1068/1068 [==============================] - 0s 139us/step - loss: 0.3575 - mean_squared_error: 0.3575 - val_loss: 0.7515 - val_mean_squared_error: 0.7515\n",
      "Epoch 184/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3596 - mean_squared_error: 0.3596 - val_loss: 0.7484 - val_mean_squared_error: 0.7484\n",
      "Epoch 185/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3403 - mean_squared_error: 0.3403 - val_loss: 0.7673 - val_mean_squared_error: 0.7673\n",
      "Epoch 186/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3937 - mean_squared_error: 0.3937 - val_loss: 0.7675 - val_mean_squared_error: 0.7675\n",
      "Epoch 187/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3739 - mean_squared_error: 0.3739 - val_loss: 0.7650 - val_mean_squared_error: 0.7650\n",
      "Epoch 188/1000\n",
      "1068/1068 [==============================] - 0s 123us/step - loss: 0.3623 - mean_squared_error: 0.3623 - val_loss: 0.7454 - val_mean_squared_error: 0.7454\n",
      "Epoch 189/1000\n",
      "1068/1068 [==============================] - 0s 109us/step - loss: 0.3945 - mean_squared_error: 0.3945 - val_loss: 0.7411 - val_mean_squared_error: 0.7411\n",
      "Epoch 190/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3719 - mean_squared_error: 0.3719 - val_loss: 0.7431 - val_mean_squared_error: 0.7431\n",
      "Epoch 191/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3997 - mean_squared_error: 0.3997 - val_loss: 0.7640 - val_mean_squared_error: 0.7640\n",
      "Epoch 192/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.7421 - val_mean_squared_error: 0.7421\n",
      "Epoch 193/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3541 - mean_squared_error: 0.3541 - val_loss: 0.7389 - val_mean_squared_error: 0.7389\n",
      "Epoch 194/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3739 - mean_squared_error: 0.3739 - val_loss: 0.7682 - val_mean_squared_error: 0.7682\n",
      "Epoch 195/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.4049 - mean_squared_error: 0.4049 - val_loss: 0.7835 - val_mean_squared_error: 0.7835\n",
      "Epoch 196/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3364 - mean_squared_error: 0.3364 - val_loss: 0.7444 - val_mean_squared_error: 0.7444\n",
      "Epoch 197/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3601 - mean_squared_error: 0.3601 - val_loss: 0.7462 - val_mean_squared_error: 0.7462\n",
      "Epoch 198/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3444 - mean_squared_error: 0.3444 - val_loss: 0.7870 - val_mean_squared_error: 0.7870\n",
      "Epoch 199/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3751 - mean_squared_error: 0.3751 - val_loss: 0.7759 - val_mean_squared_error: 0.7759\n",
      "Epoch 200/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.7627 - val_mean_squared_error: 0.7627\n",
      "Epoch 201/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3868 - mean_squared_error: 0.3868 - val_loss: 0.7747 - val_mean_squared_error: 0.7747\n",
      "Epoch 202/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3880 - mean_squared_error: 0.3880 - val_loss: 0.7499 - val_mean_squared_error: 0.7499\n",
      "Epoch 203/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3350 - mean_squared_error: 0.3350 - val_loss: 0.7400 - val_mean_squared_error: 0.7400\n",
      "Epoch 204/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3587 - mean_squared_error: 0.3587 - val_loss: 0.7622 - val_mean_squared_error: 0.7622\n",
      "Epoch 205/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3580 - mean_squared_error: 0.3580 - val_loss: 0.7987 - val_mean_squared_error: 0.7987\n",
      "Epoch 206/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.3605 - mean_squared_error: 0.3605 - val_loss: 0.7498 - val_mean_squared_error: 0.7498\n",
      "Epoch 207/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3782 - mean_squared_error: 0.3782 - val_loss: 0.7610 - val_mean_squared_error: 0.7610\n",
      "Epoch 208/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.7843 - val_mean_squared_error: 0.7843\n",
      "Epoch 209/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.4148 - mean_squared_error: 0.4148 - val_loss: 0.7689 - val_mean_squared_error: 0.7689\n",
      "Epoch 210/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3630 - mean_squared_error: 0.3630 - val_loss: 0.7617 - val_mean_squared_error: 0.7617\n",
      "Epoch 211/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3711 - mean_squared_error: 0.3711 - val_loss: 0.7597 - val_mean_squared_error: 0.7597\n",
      "Epoch 212/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4214 - mean_squared_error: 0.4214 - val_loss: 0.7590 - val_mean_squared_error: 0.7590\n",
      "Epoch 213/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4068 - mean_squared_error: 0.4068 - val_loss: 0.7648 - val_mean_squared_error: 0.7648\n",
      "Epoch 214/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3700 - mean_squared_error: 0.3700 - val_loss: 0.7713 - val_mean_squared_error: 0.7713\n",
      "Epoch 215/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3653 - mean_squared_error: 0.3653 - val_loss: 0.7598 - val_mean_squared_error: 0.7598\n",
      "Epoch 216/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 0.7912 - val_mean_squared_error: 0.7912\n",
      "Epoch 217/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3873 - mean_squared_error: 0.3873 - val_loss: 0.7869 - val_mean_squared_error: 0.7869\n",
      "Epoch 218/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3503 - mean_squared_error: 0.3503 - val_loss: 0.7616 - val_mean_squared_error: 0.7616\n",
      "Epoch 219/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3641 - mean_squared_error: 0.3641 - val_loss: 0.7609 - val_mean_squared_error: 0.7609\n",
      "Epoch 220/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3997 - mean_squared_error: 0.3997 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
      "Epoch 221/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3732 - mean_squared_error: 0.3732 - val_loss: 0.7314 - val_mean_squared_error: 0.7314\n",
      "Epoch 222/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3547 - mean_squared_error: 0.3547 - val_loss: 0.7773 - val_mean_squared_error: 0.7773\n",
      "Epoch 223/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3340 - mean_squared_error: 0.3340 - val_loss: 0.7387 - val_mean_squared_error: 0.7387\n",
      "Epoch 224/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3844 - mean_squared_error: 0.3844 - val_loss: 0.7735 - val_mean_squared_error: 0.7735\n",
      "Epoch 225/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3431 - mean_squared_error: 0.3431 - val_loss: 0.7584 - val_mean_squared_error: 0.7584\n",
      "Epoch 226/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3681 - mean_squared_error: 0.3681 - val_loss: 0.7971 - val_mean_squared_error: 0.7971\n",
      "Epoch 227/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3497 - mean_squared_error: 0.3497 - val_loss: 0.7615 - val_mean_squared_error: 0.7615\n",
      "Epoch 228/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3595 - mean_squared_error: 0.3595 - val_loss: 0.7900 - val_mean_squared_error: 0.7900\n",
      "Epoch 229/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3535 - mean_squared_error: 0.3535 - val_loss: 0.7760 - val_mean_squared_error: 0.7760\n",
      "Epoch 230/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.7647 - val_mean_squared_error: 0.7647\n",
      "Epoch 231/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3648 - mean_squared_error: 0.3648 - val_loss: 0.7613 - val_mean_squared_error: 0.7613\n",
      "Epoch 232/1000\n",
      "1068/1068 [==============================] - 0s 118us/step - loss: 0.3675 - mean_squared_error: 0.3675 - val_loss: 0.7861 - val_mean_squared_error: 0.7861\n",
      "Epoch 233/1000\n",
      "1068/1068 [==============================] - 0s 110us/step - loss: 0.3422 - mean_squared_error: 0.3422 - val_loss: 0.7502 - val_mean_squared_error: 0.7502\n",
      "Epoch 234/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3379 - mean_squared_error: 0.3379 - val_loss: 0.7350 - val_mean_squared_error: 0.7350\n",
      "Epoch 235/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3403 - mean_squared_error: 0.3403 - val_loss: 0.7295 - val_mean_squared_error: 0.7295\n",
      "Epoch 236/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.7705 - val_mean_squared_error: 0.7705\n",
      "Epoch 237/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3540 - mean_squared_error: 0.3540 - val_loss: 0.7623 - val_mean_squared_error: 0.7623\n",
      "Epoch 238/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3598 - mean_squared_error: 0.3598 - val_loss: 0.7584 - val_mean_squared_error: 0.7584\n",
      "Epoch 239/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3555 - mean_squared_error: 0.3555 - val_loss: 0.7731 - val_mean_squared_error: 0.7731\n",
      "Epoch 240/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3437 - mean_squared_error: 0.3437 - val_loss: 0.7500 - val_mean_squared_error: 0.7500\n",
      "Epoch 241/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.4007 - mean_squared_error: 0.4007 - val_loss: 0.7599 - val_mean_squared_error: 0.7599\n",
      "Epoch 242/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3660 - mean_squared_error: 0.3660 - val_loss: 0.7602 - val_mean_squared_error: 0.7602\n",
      "Epoch 243/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3733 - mean_squared_error: 0.3733 - val_loss: 0.7682 - val_mean_squared_error: 0.7682\n",
      "Epoch 244/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3511 - mean_squared_error: 0.3511 - val_loss: 0.7579 - val_mean_squared_error: 0.7579\n",
      "Epoch 245/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3624 - mean_squared_error: 0.3624 - val_loss: 0.7567 - val_mean_squared_error: 0.7567\n",
      "Epoch 246/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3511 - mean_squared_error: 0.3511 - val_loss: 0.7578 - val_mean_squared_error: 0.7578\n",
      "Epoch 247/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3222 - mean_squared_error: 0.3222 - val_loss: 0.7296 - val_mean_squared_error: 0.7296\n",
      "Epoch 248/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3755 - mean_squared_error: 0.3755 - val_loss: 0.7493 - val_mean_squared_error: 0.7493\n",
      "Epoch 249/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3482 - mean_squared_error: 0.3482 - val_loss: 0.7431 - val_mean_squared_error: 0.7431\n",
      "Epoch 250/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3544 - mean_squared_error: 0.3544 - val_loss: 0.7466 - val_mean_squared_error: 0.7466\n",
      "Epoch 251/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3446 - mean_squared_error: 0.3446 - val_loss: 0.7408 - val_mean_squared_error: 0.7408\n",
      "Epoch 252/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3581 - mean_squared_error: 0.3581 - val_loss: 0.7241 - val_mean_squared_error: 0.7241\n",
      "Epoch 253/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3759 - mean_squared_error: 0.3759 - val_loss: 0.7492 - val_mean_squared_error: 0.7492\n",
      "Epoch 254/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3637 - mean_squared_error: 0.3637 - val_loss: 0.7324 - val_mean_squared_error: 0.7324\n",
      "Epoch 255/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3725 - mean_squared_error: 0.3725 - val_loss: 0.7490 - val_mean_squared_error: 0.7490\n",
      "Epoch 256/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3562 - mean_squared_error: 0.3562 - val_loss: 0.7711 - val_mean_squared_error: 0.7711\n",
      "Epoch 257/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3302 - mean_squared_error: 0.3302 - val_loss: 0.7379 - val_mean_squared_error: 0.7379\n",
      "Epoch 258/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3334 - mean_squared_error: 0.3334 - val_loss: 0.7507 - val_mean_squared_error: 0.7507\n",
      "Epoch 259/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3866 - mean_squared_error: 0.3866 - val_loss: 0.7931 - val_mean_squared_error: 0.7931\n",
      "Epoch 260/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3457 - mean_squared_error: 0.3457 - val_loss: 0.7526 - val_mean_squared_error: 0.7526\n",
      "Epoch 261/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3642 - mean_squared_error: 0.3642 - val_loss: 0.7284 - val_mean_squared_error: 0.7284\n",
      "Epoch 262/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3767 - mean_squared_error: 0.3767 - val_loss: 0.7525 - val_mean_squared_error: 0.7525\n",
      "Epoch 263/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3570 - mean_squared_error: 0.3570 - val_loss: 0.7688 - val_mean_squared_error: 0.7688\n",
      "Epoch 264/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3799 - mean_squared_error: 0.3799 - val_loss: 0.7243 - val_mean_squared_error: 0.7243\n",
      "Epoch 265/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3424 - mean_squared_error: 0.3424 - val_loss: 0.7589 - val_mean_squared_error: 0.7589\n",
      "Epoch 266/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3725 - mean_squared_error: 0.3725 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
      "Epoch 267/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3462 - mean_squared_error: 0.3462 - val_loss: 0.7365 - val_mean_squared_error: 0.7365\n",
      "Epoch 268/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3511 - mean_squared_error: 0.3511 - val_loss: 0.7524 - val_mean_squared_error: 0.7524\n",
      "Epoch 269/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3836 - mean_squared_error: 0.3836 - val_loss: 0.7603 - val_mean_squared_error: 0.7603\n",
      "Epoch 270/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3387 - mean_squared_error: 0.3387 - val_loss: 0.7397 - val_mean_squared_error: 0.7397\n",
      "Epoch 271/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.7214 - val_mean_squared_error: 0.7214\n",
      "Epoch 272/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.7335 - val_mean_squared_error: 0.7335\n",
      "Epoch 273/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3390 - mean_squared_error: 0.3390 - val_loss: 0.7472 - val_mean_squared_error: 0.7472\n",
      "Epoch 274/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3750 - mean_squared_error: 0.3750 - val_loss: 0.7452 - val_mean_squared_error: 0.7452\n",
      "Epoch 275/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3700 - mean_squared_error: 0.3700 - val_loss: 0.7635 - val_mean_squared_error: 0.7635\n",
      "Epoch 276/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3498 - mean_squared_error: 0.3498 - val_loss: 0.7626 - val_mean_squared_error: 0.7626\n",
      "Epoch 277/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3775 - mean_squared_error: 0.3775 - val_loss: 0.7571 - val_mean_squared_error: 0.7571\n",
      "Epoch 278/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3496 - mean_squared_error: 0.3496 - val_loss: 0.7291 - val_mean_squared_error: 0.7291\n",
      "Epoch 279/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3622 - mean_squared_error: 0.3622 - val_loss: 0.7504 - val_mean_squared_error: 0.7504\n",
      "Epoch 280/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3782 - mean_squared_error: 0.3782 - val_loss: 0.7387 - val_mean_squared_error: 0.7387\n",
      "Epoch 281/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3692 - mean_squared_error: 0.3692 - val_loss: 0.7568 - val_mean_squared_error: 0.7568\n",
      "Epoch 282/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3315 - mean_squared_error: 0.3315 - val_loss: 0.7440 - val_mean_squared_error: 0.7440\n",
      "Epoch 283/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3451 - mean_squared_error: 0.3451 - val_loss: 0.7305 - val_mean_squared_error: 0.7305\n",
      "Epoch 284/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3358 - mean_squared_error: 0.3358 - val_loss: 0.7565 - val_mean_squared_error: 0.7565\n",
      "Epoch 285/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3501 - mean_squared_error: 0.3501 - val_loss: 0.7671 - val_mean_squared_error: 0.7671\n",
      "Epoch 286/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3373 - mean_squared_error: 0.3373 - val_loss: 0.7507 - val_mean_squared_error: 0.7507\n",
      "Epoch 287/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.7333 - val_mean_squared_error: 0.7333\n",
      "Epoch 288/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3570 - mean_squared_error: 0.3570 - val_loss: 0.7144 - val_mean_squared_error: 0.7144\n",
      "Epoch 289/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3577 - mean_squared_error: 0.3577 - val_loss: 0.7029 - val_mean_squared_error: 0.7029\n",
      "Epoch 290/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3487 - mean_squared_error: 0.3487 - val_loss: 0.7334 - val_mean_squared_error: 0.7334\n",
      "Epoch 291/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3634 - mean_squared_error: 0.3634 - val_loss: 0.7515 - val_mean_squared_error: 0.7515\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3640 - mean_squared_error: 0.3640 - val_loss: 0.7345 - val_mean_squared_error: 0.7345\n",
      "Epoch 293/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3535 - mean_squared_error: 0.3535 - val_loss: 0.7340 - val_mean_squared_error: 0.7340\n",
      "Epoch 294/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.7322 - val_mean_squared_error: 0.7322\n",
      "Epoch 295/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3307 - mean_squared_error: 0.3307 - val_loss: 0.7260 - val_mean_squared_error: 0.7260\n",
      "Epoch 296/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3430 - mean_squared_error: 0.3430 - val_loss: 0.7782 - val_mean_squared_error: 0.7782\n",
      "Epoch 297/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3600 - mean_squared_error: 0.3600 - val_loss: 0.8037 - val_mean_squared_error: 0.8037\n",
      "Epoch 298/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3592 - mean_squared_error: 0.3592 - val_loss: 0.7223 - val_mean_squared_error: 0.7223\n",
      "Epoch 299/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3876 - mean_squared_error: 0.3876 - val_loss: 0.7456 - val_mean_squared_error: 0.7456\n",
      "Epoch 300/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3400 - mean_squared_error: 0.3400 - val_loss: 0.7482 - val_mean_squared_error: 0.7482\n",
      "Epoch 301/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3972 - mean_squared_error: 0.3972 - val_loss: 0.7476 - val_mean_squared_error: 0.7476\n",
      "Epoch 302/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3466 - mean_squared_error: 0.3466 - val_loss: 0.7564 - val_mean_squared_error: 0.7564\n",
      "Epoch 303/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3608 - mean_squared_error: 0.3608 - val_loss: 0.7575 - val_mean_squared_error: 0.7575\n",
      "Epoch 304/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3612 - mean_squared_error: 0.3612 - val_loss: 0.7763 - val_mean_squared_error: 0.7763\n",
      "Epoch 305/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3506 - mean_squared_error: 0.3506 - val_loss: 0.7396 - val_mean_squared_error: 0.7396\n",
      "Epoch 306/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3673 - mean_squared_error: 0.3673 - val_loss: 0.7483 - val_mean_squared_error: 0.7483\n",
      "Epoch 307/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3614 - mean_squared_error: 0.3614 - val_loss: 0.8099 - val_mean_squared_error: 0.8099\n",
      "Epoch 308/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.3459 - mean_squared_error: 0.3459 - val_loss: 0.7380 - val_mean_squared_error: 0.7380\n",
      "Epoch 309/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3837 - mean_squared_error: 0.3837 - val_loss: 0.7417 - val_mean_squared_error: 0.7417\n",
      "Epoch 310/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3746 - mean_squared_error: 0.3746 - val_loss: 0.7563 - val_mean_squared_error: 0.7563\n",
      "Epoch 311/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3779 - mean_squared_error: 0.3779 - val_loss: 0.8014 - val_mean_squared_error: 0.8014\n",
      "Epoch 312/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3464 - mean_squared_error: 0.3464 - val_loss: 0.7894 - val_mean_squared_error: 0.7894\n",
      "Epoch 313/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3684 - mean_squared_error: 0.3684 - val_loss: 0.7692 - val_mean_squared_error: 0.7692\n",
      "Epoch 314/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.4060 - mean_squared_error: 0.4060 - val_loss: 0.7466 - val_mean_squared_error: 0.7466\n",
      "Epoch 315/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3769 - mean_squared_error: 0.3769 - val_loss: 0.7397 - val_mean_squared_error: 0.7397\n",
      "Epoch 316/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3533 - mean_squared_error: 0.3533 - val_loss: 0.7735 - val_mean_squared_error: 0.7735\n",
      "Epoch 317/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3440 - mean_squared_error: 0.3440 - val_loss: 0.7862 - val_mean_squared_error: 0.7862\n",
      "Epoch 318/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3609 - mean_squared_error: 0.3609 - val_loss: 0.7613 - val_mean_squared_error: 0.7613\n",
      "Epoch 319/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3380 - mean_squared_error: 0.3380 - val_loss: 0.7863 - val_mean_squared_error: 0.7863\n",
      "Epoch 320/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3713 - mean_squared_error: 0.3713 - val_loss: 0.7412 - val_mean_squared_error: 0.7412\n",
      "Epoch 321/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3267 - mean_squared_error: 0.3267 - val_loss: 0.7725 - val_mean_squared_error: 0.7725\n",
      "Epoch 322/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3782 - mean_squared_error: 0.3782 - val_loss: 0.7270 - val_mean_squared_error: 0.7270\n",
      "Epoch 323/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3556 - mean_squared_error: 0.3556 - val_loss: 0.7321 - val_mean_squared_error: 0.7321\n",
      "Epoch 324/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3611 - mean_squared_error: 0.3611 - val_loss: 0.7481 - val_mean_squared_error: 0.7481\n",
      "Epoch 325/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3202 - mean_squared_error: 0.3202 - val_loss: 0.7651 - val_mean_squared_error: 0.7651\n",
      "Epoch 326/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3681 - mean_squared_error: 0.3681 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
      "Epoch 327/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3921 - mean_squared_error: 0.3921 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
      "Epoch 328/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3360 - mean_squared_error: 0.3360 - val_loss: 0.7608 - val_mean_squared_error: 0.7608\n",
      "Epoch 329/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3315 - mean_squared_error: 0.3315 - val_loss: 0.7514 - val_mean_squared_error: 0.7514\n",
      "Epoch 330/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.7492 - val_mean_squared_error: 0.7492\n",
      "Epoch 331/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3438 - mean_squared_error: 0.3438 - val_loss: 0.7484 - val_mean_squared_error: 0.7484\n",
      "Epoch 332/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3568 - mean_squared_error: 0.3568 - val_loss: 0.7610 - val_mean_squared_error: 0.7610\n",
      "Epoch 333/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3220 - mean_squared_error: 0.3220 - val_loss: 0.7307 - val_mean_squared_error: 0.7307\n",
      "Epoch 334/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3506 - mean_squared_error: 0.3506 - val_loss: 0.7361 - val_mean_squared_error: 0.7361\n",
      "Epoch 335/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.7253 - val_mean_squared_error: 0.7253\n",
      "Epoch 336/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3774 - mean_squared_error: 0.3774 - val_loss: 0.7440 - val_mean_squared_error: 0.7440\n",
      "Epoch 337/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3499 - mean_squared_error: 0.3499 - val_loss: 0.7795 - val_mean_squared_error: 0.7795\n",
      "Epoch 338/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.7346 - val_mean_squared_error: 0.7346\n",
      "Epoch 339/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3741 - mean_squared_error: 0.3741 - val_loss: 0.7319 - val_mean_squared_error: 0.7319\n",
      "Epoch 340/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.7422 - val_mean_squared_error: 0.7422\n",
      "Epoch 341/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3499 - mean_squared_error: 0.3499 - val_loss: 0.7304 - val_mean_squared_error: 0.7304\n",
      "Epoch 342/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3643 - mean_squared_error: 0.3643 - val_loss: 0.7567 - val_mean_squared_error: 0.7567\n",
      "Epoch 343/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3744 - mean_squared_error: 0.3744 - val_loss: 0.7151 - val_mean_squared_error: 0.7151\n",
      "Epoch 344/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.4038 - mean_squared_error: 0.4038 - val_loss: 0.7556 - val_mean_squared_error: 0.7556\n",
      "Epoch 345/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3570 - mean_squared_error: 0.3570 - val_loss: 0.7086 - val_mean_squared_error: 0.7086\n",
      "Epoch 346/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3435 - mean_squared_error: 0.3435 - val_loss: 0.7553 - val_mean_squared_error: 0.7553\n",
      "Epoch 347/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3388 - mean_squared_error: 0.3388 - val_loss: 0.7414 - val_mean_squared_error: 0.7414\n",
      "Epoch 348/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3456 - mean_squared_error: 0.3456 - val_loss: 0.7312 - val_mean_squared_error: 0.7312\n",
      "Epoch 349/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.2870 - mean_squared_error: 0.2870 - val_loss: 0.7765 - val_mean_squared_error: 0.7765\n",
      "Epoch 350/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3712 - mean_squared_error: 0.3712 - val_loss: 0.7321 - val_mean_squared_error: 0.7321\n",
      "Epoch 351/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3304 - mean_squared_error: 0.3304 - val_loss: 0.7376 - val_mean_squared_error: 0.7376\n",
      "Epoch 352/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.7716 - val_mean_squared_error: 0.7716\n",
      "Epoch 353/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.7317 - val_mean_squared_error: 0.7317\n",
      "Epoch 354/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3355 - mean_squared_error: 0.3355 - val_loss: 0.7319 - val_mean_squared_error: 0.7319\n",
      "Epoch 355/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3590 - mean_squared_error: 0.3590 - val_loss: 0.7068 - val_mean_squared_error: 0.7068\n",
      "Epoch 356/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3491 - mean_squared_error: 0.3491 - val_loss: 0.7308 - val_mean_squared_error: 0.7308\n",
      "Epoch 357/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3440 - mean_squared_error: 0.3440 - val_loss: 0.7191 - val_mean_squared_error: 0.7191\n",
      "Epoch 358/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3567 - mean_squared_error: 0.3567 - val_loss: 0.7358 - val_mean_squared_error: 0.7358\n",
      "Epoch 359/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.7282 - val_mean_squared_error: 0.7282\n",
      "Epoch 360/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3057 - mean_squared_error: 0.3057 - val_loss: 0.7181 - val_mean_squared_error: 0.7181\n",
      "Epoch 361/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3560 - mean_squared_error: 0.3560 - val_loss: 0.7420 - val_mean_squared_error: 0.7420\n",
      "Epoch 362/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3215 - mean_squared_error: 0.3215 - val_loss: 0.7287 - val_mean_squared_error: 0.7287\n",
      "Epoch 363/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3949 - mean_squared_error: 0.3949 - val_loss: 0.7882 - val_mean_squared_error: 0.7882\n",
      "Epoch 364/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.7236 - val_mean_squared_error: 0.7236\n",
      "Epoch 365/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3536 - mean_squared_error: 0.3536 - val_loss: 0.7611 - val_mean_squared_error: 0.7611\n",
      "Epoch 366/1000\n",
      "1068/1068 [==============================] - 0s 114us/step - loss: 0.3541 - mean_squared_error: 0.3541 - val_loss: 0.7313 - val_mean_squared_error: 0.7313\n",
      "Epoch 367/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3373 - mean_squared_error: 0.3373 - val_loss: 0.7278 - val_mean_squared_error: 0.7278\n",
      "Epoch 368/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.7307 - val_mean_squared_error: 0.7307\n",
      "Epoch 369/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3513 - mean_squared_error: 0.3513 - val_loss: 0.7144 - val_mean_squared_error: 0.7144\n",
      "Epoch 370/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3234 - mean_squared_error: 0.3234 - val_loss: 0.7413 - val_mean_squared_error: 0.7413\n",
      "Epoch 371/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3536 - mean_squared_error: 0.3536 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
      "Epoch 372/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3736 - mean_squared_error: 0.3736 - val_loss: 0.7609 - val_mean_squared_error: 0.7609\n",
      "Epoch 373/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.7424 - val_mean_squared_error: 0.7424\n",
      "Epoch 374/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3765 - mean_squared_error: 0.3765 - val_loss: 0.7883 - val_mean_squared_error: 0.7883\n",
      "Epoch 375/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3624 - mean_squared_error: 0.3624 - val_loss: 0.7575 - val_mean_squared_error: 0.7575\n",
      "Epoch 376/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3109 - mean_squared_error: 0.3109 - val_loss: 0.7673 - val_mean_squared_error: 0.7673\n",
      "Epoch 377/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3646 - mean_squared_error: 0.3646 - val_loss: 0.7450 - val_mean_squared_error: 0.7450\n",
      "Epoch 378/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3434 - mean_squared_error: 0.3434 - val_loss: 0.7439 - val_mean_squared_error: 0.7439\n",
      "Epoch 379/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.7638 - val_mean_squared_error: 0.7638\n",
      "Epoch 380/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3759 - mean_squared_error: 0.3759 - val_loss: 0.7352 - val_mean_squared_error: 0.7352\n",
      "Epoch 381/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3495 - mean_squared_error: 0.3495 - val_loss: 0.7604 - val_mean_squared_error: 0.7604\n",
      "Epoch 382/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3417 - mean_squared_error: 0.3417 - val_loss: 0.7582 - val_mean_squared_error: 0.7582\n",
      "Epoch 383/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3700 - mean_squared_error: 0.3700 - val_loss: 0.7532 - val_mean_squared_error: 0.7532\n",
      "Epoch 384/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.7496 - val_mean_squared_error: 0.7496\n",
      "Epoch 385/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3570 - mean_squared_error: 0.3570 - val_loss: 0.7445 - val_mean_squared_error: 0.7445\n",
      "Epoch 386/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3164 - mean_squared_error: 0.3164 - val_loss: 0.7366 - val_mean_squared_error: 0.7366\n",
      "Epoch 387/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3311 - mean_squared_error: 0.3311 - val_loss: 0.7373 - val_mean_squared_error: 0.7373\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3404 - mean_squared_error: 0.3404 - val_loss: 0.7662 - val_mean_squared_error: 0.7662\n",
      "Epoch 389/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3334 - mean_squared_error: 0.3334 - val_loss: 0.7241 - val_mean_squared_error: 0.7241\n",
      "Epoch 390/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3569 - mean_squared_error: 0.3569 - val_loss: 0.7505 - val_mean_squared_error: 0.7505\n",
      "Epoch 391/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3204 - mean_squared_error: 0.3204 - val_loss: 0.7610 - val_mean_squared_error: 0.7610\n",
      "Epoch 392/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3546 - mean_squared_error: 0.3546 - val_loss: 0.7754 - val_mean_squared_error: 0.7754\n",
      "Epoch 393/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3431 - mean_squared_error: 0.3431 - val_loss: 0.7745 - val_mean_squared_error: 0.7745\n",
      "Epoch 394/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3543 - mean_squared_error: 0.3543 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n",
      "Epoch 395/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3261 - mean_squared_error: 0.3261 - val_loss: 0.7742 - val_mean_squared_error: 0.7742\n",
      "Epoch 396/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.7247 - val_mean_squared_error: 0.7247\n",
      "Epoch 397/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3322 - mean_squared_error: 0.3322 - val_loss: 0.7494 - val_mean_squared_error: 0.7494\n",
      "Epoch 398/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.7331 - val_mean_squared_error: 0.7331\n",
      "Epoch 399/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3384 - mean_squared_error: 0.3384 - val_loss: 0.7552 - val_mean_squared_error: 0.7552\n",
      "Epoch 400/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3797 - mean_squared_error: 0.3797 - val_loss: 0.7584 - val_mean_squared_error: 0.7584\n",
      "Epoch 401/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3575 - mean_squared_error: 0.3575 - val_loss: 0.7707 - val_mean_squared_error: 0.7707\n",
      "Epoch 402/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3309 - mean_squared_error: 0.3309 - val_loss: 0.7694 - val_mean_squared_error: 0.7694\n",
      "Epoch 403/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.7662 - val_mean_squared_error: 0.7662\n",
      "Epoch 404/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3725 - mean_squared_error: 0.3725 - val_loss: 0.7733 - val_mean_squared_error: 0.7733\n",
      "Epoch 405/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.2931 - mean_squared_error: 0.2931 - val_loss: 0.7615 - val_mean_squared_error: 0.7615\n",
      "Epoch 406/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3489 - mean_squared_error: 0.3489 - val_loss: 0.7570 - val_mean_squared_error: 0.7570\n",
      "Epoch 407/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3463 - mean_squared_error: 0.3463 - val_loss: 0.7553 - val_mean_squared_error: 0.7553\n",
      "Epoch 408/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3255 - mean_squared_error: 0.3255 - val_loss: 0.7427 - val_mean_squared_error: 0.7427\n",
      "Epoch 409/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3717 - mean_squared_error: 0.3717 - val_loss: 0.7811 - val_mean_squared_error: 0.7811\n",
      "Epoch 410/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3164 - mean_squared_error: 0.3164 - val_loss: 0.7517 - val_mean_squared_error: 0.7517\n",
      "Epoch 411/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3798 - mean_squared_error: 0.3798 - val_loss: 0.7374 - val_mean_squared_error: 0.7374\n",
      "Epoch 412/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3953 - mean_squared_error: 0.3953 - val_loss: 0.7586 - val_mean_squared_error: 0.7586\n",
      "Epoch 413/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3071 - mean_squared_error: 0.3071 - val_loss: 0.7527 - val_mean_squared_error: 0.7527\n",
      "Epoch 414/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3429 - mean_squared_error: 0.3429 - val_loss: 0.7527 - val_mean_squared_error: 0.7527\n",
      "Epoch 415/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3145 - mean_squared_error: 0.3145 - val_loss: 0.7400 - val_mean_squared_error: 0.7400\n",
      "Epoch 416/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3709 - mean_squared_error: 0.3709 - val_loss: 0.7692 - val_mean_squared_error: 0.7692\n",
      "Epoch 417/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3204 - mean_squared_error: 0.3204 - val_loss: 0.7399 - val_mean_squared_error: 0.7399\n",
      "Epoch 418/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3266 - mean_squared_error: 0.3266 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
      "Epoch 419/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.7581 - val_mean_squared_error: 0.7581\n",
      "Epoch 420/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3535 - mean_squared_error: 0.3535 - val_loss: 0.7268 - val_mean_squared_error: 0.7268\n",
      "Epoch 421/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3202 - mean_squared_error: 0.3202 - val_loss: 0.7259 - val_mean_squared_error: 0.7259\n",
      "Epoch 422/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.7358 - val_mean_squared_error: 0.7358\n",
      "Epoch 423/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3330 - mean_squared_error: 0.3330 - val_loss: 0.7529 - val_mean_squared_error: 0.7529\n",
      "Epoch 424/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3369 - mean_squared_error: 0.3369 - val_loss: 0.7483 - val_mean_squared_error: 0.7483\n",
      "Epoch 425/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3614 - mean_squared_error: 0.3614 - val_loss: 0.7159 - val_mean_squared_error: 0.7159\n",
      "Epoch 426/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2945 - mean_squared_error: 0.2945 - val_loss: 0.7258 - val_mean_squared_error: 0.7258\n",
      "Epoch 427/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.7507 - val_mean_squared_error: 0.7507\n",
      "Epoch 428/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3692 - mean_squared_error: 0.3692 - val_loss: 0.7574 - val_mean_squared_error: 0.7574\n",
      "Epoch 429/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3691 - mean_squared_error: 0.3691 - val_loss: 0.7408 - val_mean_squared_error: 0.7408\n",
      "Epoch 430/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3830 - mean_squared_error: 0.3830 - val_loss: 0.7518 - val_mean_squared_error: 0.7518\n",
      "Epoch 431/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3313 - mean_squared_error: 0.3313 - val_loss: 0.7229 - val_mean_squared_error: 0.7229\n",
      "Epoch 432/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3349 - mean_squared_error: 0.3349 - val_loss: 0.7697 - val_mean_squared_error: 0.7697\n",
      "Epoch 433/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3553 - mean_squared_error: 0.3553 - val_loss: 0.7433 - val_mean_squared_error: 0.7433\n",
      "Epoch 434/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3341 - mean_squared_error: 0.3341 - val_loss: 0.7247 - val_mean_squared_error: 0.7247\n",
      "Epoch 435/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3613 - mean_squared_error: 0.3613 - val_loss: 0.7963 - val_mean_squared_error: 0.7963\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.7450 - val_mean_squared_error: 0.7450\n",
      "Epoch 437/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.7626 - val_mean_squared_error: 0.7626\n",
      "Epoch 438/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3215 - mean_squared_error: 0.3215 - val_loss: 0.7436 - val_mean_squared_error: 0.7436\n",
      "Epoch 439/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3538 - mean_squared_error: 0.3538 - val_loss: 0.7464 - val_mean_squared_error: 0.7464\n",
      "Epoch 440/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3327 - mean_squared_error: 0.3327 - val_loss: 0.7672 - val_mean_squared_error: 0.7672\n",
      "Epoch 441/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.7421 - val_mean_squared_error: 0.7421\n",
      "Epoch 442/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3600 - mean_squared_error: 0.3600 - val_loss: 0.7434 - val_mean_squared_error: 0.7434\n",
      "Epoch 443/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3336 - mean_squared_error: 0.3336 - val_loss: 0.7554 - val_mean_squared_error: 0.7554\n",
      "Epoch 444/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3318 - mean_squared_error: 0.3318 - val_loss: 0.7807 - val_mean_squared_error: 0.7807\n",
      "Epoch 445/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3490 - mean_squared_error: 0.3490 - val_loss: 0.7836 - val_mean_squared_error: 0.7836\n",
      "Epoch 446/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3572 - mean_squared_error: 0.3572 - val_loss: 0.7725 - val_mean_squared_error: 0.7725\n",
      "Epoch 447/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3432 - mean_squared_error: 0.3432 - val_loss: 0.7632 - val_mean_squared_error: 0.7632\n",
      "Epoch 448/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3543 - mean_squared_error: 0.3543 - val_loss: 0.7753 - val_mean_squared_error: 0.7753\n",
      "Epoch 449/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.7557 - val_mean_squared_error: 0.7557\n",
      "Epoch 450/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3127 - mean_squared_error: 0.3127 - val_loss: 0.7729 - val_mean_squared_error: 0.7729\n",
      "Epoch 451/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3392 - mean_squared_error: 0.3392 - val_loss: 0.7609 - val_mean_squared_error: 0.7609\n",
      "Epoch 452/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3123 - mean_squared_error: 0.3123 - val_loss: 0.7587 - val_mean_squared_error: 0.7587\n",
      "Epoch 453/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3019 - mean_squared_error: 0.3019 - val_loss: 0.7689 - val_mean_squared_error: 0.7689\n",
      "Epoch 454/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3481 - mean_squared_error: 0.3481 - val_loss: 0.7346 - val_mean_squared_error: 0.7346\n",
      "Epoch 455/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3021 - mean_squared_error: 0.3021 - val_loss: 0.7377 - val_mean_squared_error: 0.7377\n",
      "Epoch 456/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.7869 - val_mean_squared_error: 0.7869\n",
      "Epoch 457/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.7567 - val_mean_squared_error: 0.7567\n",
      "Epoch 458/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3487 - mean_squared_error: 0.3487 - val_loss: 0.7446 - val_mean_squared_error: 0.7446\n",
      "Epoch 459/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3613 - mean_squared_error: 0.3613 - val_loss: 0.7429 - val_mean_squared_error: 0.7429\n",
      "Epoch 460/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3162 - mean_squared_error: 0.3162 - val_loss: 0.7447 - val_mean_squared_error: 0.7447\n",
      "Epoch 461/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3569 - mean_squared_error: 0.3569 - val_loss: 0.7446 - val_mean_squared_error: 0.7446\n",
      "Epoch 462/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3118 - mean_squared_error: 0.3118 - val_loss: 0.7494 - val_mean_squared_error: 0.7494\n",
      "Epoch 463/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3207 - mean_squared_error: 0.3207 - val_loss: 0.7312 - val_mean_squared_error: 0.7312\n",
      "Epoch 464/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3308 - mean_squared_error: 0.3308 - val_loss: 0.7482 - val_mean_squared_error: 0.7482\n",
      "Epoch 465/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3139 - mean_squared_error: 0.3139 - val_loss: 0.7196 - val_mean_squared_error: 0.7196\n",
      "Epoch 466/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.7356 - val_mean_squared_error: 0.7356\n",
      "Epoch 467/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3336 - mean_squared_error: 0.3336 - val_loss: 0.7602 - val_mean_squared_error: 0.7602\n",
      "Epoch 468/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3616 - mean_squared_error: 0.3616 - val_loss: 0.7451 - val_mean_squared_error: 0.7451\n",
      "Epoch 469/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3374 - mean_squared_error: 0.3374 - val_loss: 0.7260 - val_mean_squared_error: 0.7260\n",
      "Epoch 470/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3592 - mean_squared_error: 0.3592 - val_loss: 0.7603 - val_mean_squared_error: 0.7603\n",
      "Epoch 471/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3532 - mean_squared_error: 0.3532 - val_loss: 0.7247 - val_mean_squared_error: 0.7247\n",
      "Epoch 472/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3605 - mean_squared_error: 0.3605 - val_loss: 0.7257 - val_mean_squared_error: 0.7257\n",
      "Epoch 473/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3128 - mean_squared_error: 0.3128 - val_loss: 0.7336 - val_mean_squared_error: 0.7336\n",
      "Epoch 474/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3496 - mean_squared_error: 0.3496 - val_loss: 0.7230 - val_mean_squared_error: 0.7230\n",
      "Epoch 475/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.7406 - val_mean_squared_error: 0.7406\n",
      "Epoch 476/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3716 - mean_squared_error: 0.3716 - val_loss: 0.7370 - val_mean_squared_error: 0.7370\n",
      "Epoch 477/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3346 - mean_squared_error: 0.3346 - val_loss: 0.7152 - val_mean_squared_error: 0.7152\n",
      "Epoch 478/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3374 - mean_squared_error: 0.3374 - val_loss: 0.7236 - val_mean_squared_error: 0.7236\n",
      "Epoch 479/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3740 - mean_squared_error: 0.3740 - val_loss: 0.7707 - val_mean_squared_error: 0.7707\n",
      "Epoch 480/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.7517 - val_mean_squared_error: 0.7517\n",
      "Epoch 481/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3458 - mean_squared_error: 0.3458 - val_loss: 0.7552 - val_mean_squared_error: 0.7552\n",
      "Epoch 482/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3486 - mean_squared_error: 0.3486 - val_loss: 0.7268 - val_mean_squared_error: 0.7268\n",
      "Epoch 483/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3276 - mean_squared_error: 0.3276 - val_loss: 0.7422 - val_mean_squared_error: 0.7422\n",
      "Epoch 484/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3461 - mean_squared_error: 0.3461 - val_loss: 0.7528 - val_mean_squared_error: 0.7528\n",
      "Epoch 485/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.3213 - mean_squared_error: 0.3213 - val_loss: 0.7444 - val_mean_squared_error: 0.7444\n",
      "Epoch 486/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3708 - mean_squared_error: 0.3708 - val_loss: 0.7314 - val_mean_squared_error: 0.7314\n",
      "Epoch 487/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3566 - mean_squared_error: 0.3566 - val_loss: 0.7662 - val_mean_squared_error: 0.7662\n",
      "Epoch 488/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3212 - mean_squared_error: 0.3212 - val_loss: 0.7731 - val_mean_squared_error: 0.7731\n",
      "Epoch 489/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3349 - mean_squared_error: 0.3349 - val_loss: 0.7332 - val_mean_squared_error: 0.7332\n",
      "Epoch 490/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3450 - mean_squared_error: 0.3450 - val_loss: 0.7371 - val_mean_squared_error: 0.7371\n",
      "Epoch 491/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3430 - mean_squared_error: 0.3430 - val_loss: 0.7460 - val_mean_squared_error: 0.7460\n",
      "Epoch 492/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3354 - mean_squared_error: 0.3354 - val_loss: 0.7301 - val_mean_squared_error: 0.7301\n",
      "Epoch 493/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3368 - mean_squared_error: 0.3368 - val_loss: 0.7547 - val_mean_squared_error: 0.7547\n",
      "Epoch 494/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3168 - mean_squared_error: 0.3168 - val_loss: 0.7346 - val_mean_squared_error: 0.7346\n",
      "Epoch 495/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3338 - mean_squared_error: 0.3338 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
      "Epoch 496/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3434 - mean_squared_error: 0.3434 - val_loss: 0.7518 - val_mean_squared_error: 0.7518\n",
      "Epoch 497/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3425 - mean_squared_error: 0.3425 - val_loss: 0.7342 - val_mean_squared_error: 0.7342\n",
      "Epoch 498/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.7476 - val_mean_squared_error: 0.7476\n",
      "Epoch 499/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3265 - mean_squared_error: 0.3265 - val_loss: 0.7271 - val_mean_squared_error: 0.7271\n",
      "Epoch 500/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3443 - mean_squared_error: 0.3443 - val_loss: 0.7342 - val_mean_squared_error: 0.7342\n",
      "Epoch 501/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3354 - mean_squared_error: 0.3354 - val_loss: 0.7459 - val_mean_squared_error: 0.7459\n",
      "Epoch 502/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.7335 - val_mean_squared_error: 0.7335\n",
      "Epoch 503/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3083 - mean_squared_error: 0.3083 - val_loss: 0.7556 - val_mean_squared_error: 0.7556\n",
      "Epoch 504/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3119 - mean_squared_error: 0.3119 - val_loss: 0.7399 - val_mean_squared_error: 0.7399\n",
      "Epoch 505/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.7274 - val_mean_squared_error: 0.7274\n",
      "Epoch 506/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3562 - mean_squared_error: 0.3562 - val_loss: 0.7213 - val_mean_squared_error: 0.7213\n",
      "Epoch 507/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3391 - mean_squared_error: 0.3391 - val_loss: 0.7401 - val_mean_squared_error: 0.7401\n",
      "Epoch 508/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3363 - mean_squared_error: 0.3363 - val_loss: 0.7084 - val_mean_squared_error: 0.7084\n",
      "Epoch 509/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3497 - mean_squared_error: 0.3497 - val_loss: 0.7141 - val_mean_squared_error: 0.7141\n",
      "Epoch 510/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3443 - mean_squared_error: 0.3443 - val_loss: 0.7425 - val_mean_squared_error: 0.7425\n",
      "Epoch 511/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3607 - mean_squared_error: 0.3607 - val_loss: 0.7407 - val_mean_squared_error: 0.7407\n",
      "Epoch 512/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3525 - mean_squared_error: 0.3525 - val_loss: 0.7174 - val_mean_squared_error: 0.7174\n",
      "Epoch 513/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3468 - mean_squared_error: 0.3468 - val_loss: 0.7341 - val_mean_squared_error: 0.7341\n",
      "Epoch 514/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3511 - mean_squared_error: 0.3511 - val_loss: 0.7248 - val_mean_squared_error: 0.7248\n",
      "Epoch 515/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3728 - mean_squared_error: 0.3728 - val_loss: 0.7317 - val_mean_squared_error: 0.7317\n",
      "Epoch 516/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.7391 - val_mean_squared_error: 0.7391\n",
      "Epoch 517/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3422 - mean_squared_error: 0.3422 - val_loss: 0.7250 - val_mean_squared_error: 0.7250\n",
      "Epoch 518/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3717 - mean_squared_error: 0.3717 - val_loss: 0.7253 - val_mean_squared_error: 0.7253\n",
      "Epoch 519/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3406 - mean_squared_error: 0.3406 - val_loss: 0.7175 - val_mean_squared_error: 0.7175\n",
      "Epoch 520/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3388 - mean_squared_error: 0.3388 - val_loss: 0.7228 - val_mean_squared_error: 0.7228\n",
      "Epoch 521/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.7411 - val_mean_squared_error: 0.7411\n",
      "Epoch 522/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3434 - mean_squared_error: 0.3434 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
      "Epoch 523/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3544 - mean_squared_error: 0.3544 - val_loss: 0.7516 - val_mean_squared_error: 0.7516\n",
      "Epoch 524/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3454 - mean_squared_error: 0.3454 - val_loss: 0.7317 - val_mean_squared_error: 0.7317\n",
      "Epoch 525/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3350 - mean_squared_error: 0.3350 - val_loss: 0.7157 - val_mean_squared_error: 0.7157\n",
      "Epoch 526/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3492 - mean_squared_error: 0.3492 - val_loss: 0.7444 - val_mean_squared_error: 0.7444\n",
      "Epoch 527/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3241 - mean_squared_error: 0.3241 - val_loss: 0.7137 - val_mean_squared_error: 0.7137\n",
      "Epoch 528/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3198 - mean_squared_error: 0.3198 - val_loss: 0.7097 - val_mean_squared_error: 0.7097\n",
      "Epoch 529/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.7600 - val_mean_squared_error: 0.7600\n",
      "Epoch 530/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3308 - mean_squared_error: 0.3308 - val_loss: 0.7229 - val_mean_squared_error: 0.7229\n",
      "Epoch 531/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3377 - mean_squared_error: 0.3377 - val_loss: 0.7593 - val_mean_squared_error: 0.7593\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3061 - mean_squared_error: 0.3061 - val_loss: 0.7646 - val_mean_squared_error: 0.7646\n",
      "Epoch 533/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3817 - mean_squared_error: 0.3817 - val_loss: 0.7163 - val_mean_squared_error: 0.7163\n",
      "Epoch 534/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3792 - mean_squared_error: 0.3792 - val_loss: 0.7250 - val_mean_squared_error: 0.7250\n",
      "Epoch 535/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3478 - mean_squared_error: 0.3478 - val_loss: 0.7491 - val_mean_squared_error: 0.7491\n",
      "Epoch 536/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3405 - mean_squared_error: 0.3405 - val_loss: 0.7226 - val_mean_squared_error: 0.7226\n",
      "Epoch 537/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3502 - mean_squared_error: 0.3502 - val_loss: 0.7349 - val_mean_squared_error: 0.7349\n",
      "Epoch 538/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3468 - mean_squared_error: 0.3468 - val_loss: 0.7561 - val_mean_squared_error: 0.7561\n",
      "Epoch 539/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3384 - mean_squared_error: 0.3384 - val_loss: 0.7452 - val_mean_squared_error: 0.7452\n",
      "Epoch 540/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3444 - mean_squared_error: 0.3444 - val_loss: 0.7501 - val_mean_squared_error: 0.7501\n",
      "Epoch 541/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3206 - mean_squared_error: 0.3206 - val_loss: 0.7203 - val_mean_squared_error: 0.7203\n",
      "Epoch 542/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3452 - mean_squared_error: 0.3452 - val_loss: 0.7457 - val_mean_squared_error: 0.7457\n",
      "Epoch 543/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3498 - mean_squared_error: 0.3498 - val_loss: 0.7307 - val_mean_squared_error: 0.7307\n",
      "Epoch 544/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.7456 - val_mean_squared_error: 0.7456\n",
      "Epoch 545/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3565 - mean_squared_error: 0.3565 - val_loss: 0.7309 - val_mean_squared_error: 0.7309\n",
      "Epoch 546/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3051 - mean_squared_error: 0.3051 - val_loss: 0.7226 - val_mean_squared_error: 0.7226\n",
      "Epoch 547/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3426 - mean_squared_error: 0.3426 - val_loss: 0.7360 - val_mean_squared_error: 0.7360\n",
      "Epoch 548/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3670 - mean_squared_error: 0.3670 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 549/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3304 - mean_squared_error: 0.3304 - val_loss: 0.7379 - val_mean_squared_error: 0.7379\n",
      "Epoch 550/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.7348 - val_mean_squared_error: 0.7348\n",
      "Epoch 551/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3409 - mean_squared_error: 0.3409 - val_loss: 0.7128 - val_mean_squared_error: 0.7128\n",
      "Epoch 552/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.7443 - val_mean_squared_error: 0.7443\n",
      "Epoch 553/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3539 - mean_squared_error: 0.3539 - val_loss: 0.7272 - val_mean_squared_error: 0.7272\n",
      "Epoch 554/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.2835 - mean_squared_error: 0.2835 - val_loss: 0.7521 - val_mean_squared_error: 0.7521\n",
      "Epoch 555/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3625 - mean_squared_error: 0.3625 - val_loss: 0.7078 - val_mean_squared_error: 0.7078\n",
      "Epoch 556/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2972 - mean_squared_error: 0.2972 - val_loss: 0.7461 - val_mean_squared_error: 0.7461\n",
      "Epoch 557/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3265 - mean_squared_error: 0.3265 - val_loss: 0.7367 - val_mean_squared_error: 0.7367\n",
      "Epoch 558/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3196 - mean_squared_error: 0.3196 - val_loss: 0.7430 - val_mean_squared_error: 0.7430\n",
      "Epoch 559/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3093 - mean_squared_error: 0.3093 - val_loss: 0.7237 - val_mean_squared_error: 0.7237\n",
      "Epoch 560/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3352 - mean_squared_error: 0.3352 - val_loss: 0.7322 - val_mean_squared_error: 0.7322\n",
      "Epoch 561/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3283 - mean_squared_error: 0.3283 - val_loss: 0.7198 - val_mean_squared_error: 0.7198\n",
      "Epoch 562/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3255 - mean_squared_error: 0.3255 - val_loss: 0.7412 - val_mean_squared_error: 0.7412\n",
      "Epoch 563/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3370 - mean_squared_error: 0.3370 - val_loss: 0.7186 - val_mean_squared_error: 0.7186\n",
      "Epoch 564/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3527 - mean_squared_error: 0.3527 - val_loss: 0.7443 - val_mean_squared_error: 0.7443\n",
      "Epoch 565/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3587 - mean_squared_error: 0.3587 - val_loss: 0.7367 - val_mean_squared_error: 0.7367\n",
      "Epoch 566/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3400 - mean_squared_error: 0.3400 - val_loss: 0.7438 - val_mean_squared_error: 0.7438\n",
      "Epoch 567/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3408 - mean_squared_error: 0.3408 - val_loss: 0.7278 - val_mean_squared_error: 0.7278\n",
      "Epoch 568/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3407 - mean_squared_error: 0.3407 - val_loss: 0.7379 - val_mean_squared_error: 0.7379\n",
      "Epoch 569/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3386 - mean_squared_error: 0.3386 - val_loss: 0.7138 - val_mean_squared_error: 0.7138\n",
      "Epoch 570/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3157 - mean_squared_error: 0.3157 - val_loss: 0.7251 - val_mean_squared_error: 0.7251\n",
      "Epoch 571/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3468 - mean_squared_error: 0.3468 - val_loss: 0.7854 - val_mean_squared_error: 0.7854\n",
      "Epoch 572/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3361 - mean_squared_error: 0.3361 - val_loss: 0.7296 - val_mean_squared_error: 0.7296\n",
      "Epoch 573/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3429 - mean_squared_error: 0.3429 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n",
      "Epoch 574/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3387 - mean_squared_error: 0.3387 - val_loss: 0.7039 - val_mean_squared_error: 0.7039\n",
      "Epoch 575/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3306 - mean_squared_error: 0.3306 - val_loss: 0.7332 - val_mean_squared_error: 0.7332\n",
      "Epoch 576/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3597 - mean_squared_error: 0.3597 - val_loss: 0.7145 - val_mean_squared_error: 0.7145\n",
      "Epoch 577/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3723 - mean_squared_error: 0.3723 - val_loss: 0.7684 - val_mean_squared_error: 0.7684\n",
      "Epoch 578/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3188 - mean_squared_error: 0.3188 - val_loss: 0.7315 - val_mean_squared_error: 0.7315\n",
      "Epoch 579/1000\n",
      "1068/1068 [==============================] - 0s 109us/step - loss: 0.3605 - mean_squared_error: 0.3605 - val_loss: 0.7410 - val_mean_squared_error: 0.7410\n",
      "Epoch 580/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 119us/step - loss: 0.3128 - mean_squared_error: 0.3128 - val_loss: 0.7370 - val_mean_squared_error: 0.7370\n",
      "Epoch 581/1000\n",
      "1068/1068 [==============================] - 0s 117us/step - loss: 0.3470 - mean_squared_error: 0.3470 - val_loss: 0.7348 - val_mean_squared_error: 0.7348\n",
      "Epoch 582/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3326 - mean_squared_error: 0.3326 - val_loss: 0.7324 - val_mean_squared_error: 0.7324\n",
      "Epoch 583/1000\n",
      "1068/1068 [==============================] - 0s 120us/step - loss: 0.3071 - mean_squared_error: 0.3071 - val_loss: 0.7344 - val_mean_squared_error: 0.7344\n",
      "Epoch 584/1000\n",
      "1068/1068 [==============================] - 0s 116us/step - loss: 0.3543 - mean_squared_error: 0.3543 - val_loss: 0.7038 - val_mean_squared_error: 0.7038\n",
      "Epoch 585/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3136 - mean_squared_error: 0.3136 - val_loss: 0.7093 - val_mean_squared_error: 0.7093\n",
      "Epoch 586/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3443 - mean_squared_error: 0.3443 - val_loss: 0.7375 - val_mean_squared_error: 0.7375\n",
      "Epoch 587/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3560 - mean_squared_error: 0.3560 - val_loss: 0.7292 - val_mean_squared_error: 0.7292\n",
      "Epoch 588/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3411 - mean_squared_error: 0.3411 - val_loss: 0.7229 - val_mean_squared_error: 0.7229\n",
      "Epoch 589/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3224 - mean_squared_error: 0.3224 - val_loss: 0.7674 - val_mean_squared_error: 0.7674\n",
      "Epoch 590/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3866 - mean_squared_error: 0.3866 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
      "Epoch 591/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3351 - mean_squared_error: 0.3351 - val_loss: 0.7292 - val_mean_squared_error: 0.7292\n",
      "Epoch 592/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3329 - mean_squared_error: 0.3329 - val_loss: 0.7217 - val_mean_squared_error: 0.7217\n",
      "Epoch 593/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3362 - mean_squared_error: 0.3362 - val_loss: 0.7156 - val_mean_squared_error: 0.7156\n",
      "Epoch 594/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3323 - mean_squared_error: 0.3323 - val_loss: 0.7022 - val_mean_squared_error: 0.7022\n",
      "Epoch 595/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.7494 - val_mean_squared_error: 0.7494\n",
      "Epoch 596/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3339 - mean_squared_error: 0.3339 - val_loss: 0.7153 - val_mean_squared_error: 0.7153\n",
      "Epoch 597/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2933 - mean_squared_error: 0.2933 - val_loss: 0.6992 - val_mean_squared_error: 0.6992\n",
      "Epoch 598/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3149 - mean_squared_error: 0.3149 - val_loss: 0.7318 - val_mean_squared_error: 0.7318\n",
      "Epoch 599/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.2924 - mean_squared_error: 0.2924 - val_loss: 0.7119 - val_mean_squared_error: 0.7119\n",
      "Epoch 600/1000\n",
      "1068/1068 [==============================] - 0s 116us/step - loss: 0.2995 - mean_squared_error: 0.2995 - val_loss: 0.7466 - val_mean_squared_error: 0.7466\n",
      "Epoch 601/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3597 - mean_squared_error: 0.3597 - val_loss: 0.7240 - val_mean_squared_error: 0.7240\n",
      "Epoch 602/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3089 - mean_squared_error: 0.3089 - val_loss: 0.7403 - val_mean_squared_error: 0.7403\n",
      "Epoch 603/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3348 - mean_squared_error: 0.3348 - val_loss: 0.7192 - val_mean_squared_error: 0.7192\n",
      "Epoch 604/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3614 - mean_squared_error: 0.3614 - val_loss: 0.7158 - val_mean_squared_error: 0.7158\n",
      "Epoch 605/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3595 - mean_squared_error: 0.3595 - val_loss: 0.7292 - val_mean_squared_error: 0.7292\n",
      "Epoch 606/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2968 - mean_squared_error: 0.2968 - val_loss: 0.7331 - val_mean_squared_error: 0.7331\n",
      "Epoch 607/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3551 - mean_squared_error: 0.3551 - val_loss: 0.7447 - val_mean_squared_error: 0.7447\n",
      "Epoch 608/1000\n",
      "1068/1068 [==============================] - 0s 109us/step - loss: 0.3487 - mean_squared_error: 0.3487 - val_loss: 0.7264 - val_mean_squared_error: 0.7264\n",
      "Epoch 609/1000\n",
      "1068/1068 [==============================] - 0s 109us/step - loss: 0.3404 - mean_squared_error: 0.3404 - val_loss: 0.7283 - val_mean_squared_error: 0.7283\n",
      "Epoch 610/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3562 - mean_squared_error: 0.3562 - val_loss: 0.7329 - val_mean_squared_error: 0.7329\n",
      "Epoch 611/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3501 - mean_squared_error: 0.3501 - val_loss: 0.7201 - val_mean_squared_error: 0.7201\n",
      "Epoch 612/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3458 - mean_squared_error: 0.3458 - val_loss: 0.7253 - val_mean_squared_error: 0.7253\n",
      "Epoch 613/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3262 - mean_squared_error: 0.3262 - val_loss: 0.7222 - val_mean_squared_error: 0.7222\n",
      "Epoch 614/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3082 - mean_squared_error: 0.3082 - val_loss: 0.7116 - val_mean_squared_error: 0.7116\n",
      "Epoch 615/1000\n",
      "1068/1068 [==============================] - 0s 121us/step - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.7243 - val_mean_squared_error: 0.7243\n",
      "Epoch 616/1000\n",
      "1068/1068 [==============================] - 0s 113us/step - loss: 0.3187 - mean_squared_error: 0.3187 - val_loss: 0.7325 - val_mean_squared_error: 0.7325\n",
      "Epoch 617/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3469 - mean_squared_error: 0.3469 - val_loss: 0.7219 - val_mean_squared_error: 0.7219\n",
      "Epoch 618/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3737 - mean_squared_error: 0.3737 - val_loss: 0.7363 - val_mean_squared_error: 0.7363\n",
      "Epoch 619/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.2907 - mean_squared_error: 0.2907 - val_loss: 0.7409 - val_mean_squared_error: 0.7409\n",
      "Epoch 620/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3327 - mean_squared_error: 0.3327 - val_loss: 0.7303 - val_mean_squared_error: 0.7303\n",
      "Epoch 621/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3208 - mean_squared_error: 0.3208 - val_loss: 0.7579 - val_mean_squared_error: 0.7579\n",
      "Epoch 622/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3288 - mean_squared_error: 0.3288 - val_loss: 0.7659 - val_mean_squared_error: 0.7659\n",
      "Epoch 623/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3166 - mean_squared_error: 0.3166 - val_loss: 0.7215 - val_mean_squared_error: 0.7215\n",
      "Epoch 624/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3831 - mean_squared_error: 0.3831 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
      "Epoch 625/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3457 - mean_squared_error: 0.3457 - val_loss: 0.7325 - val_mean_squared_error: 0.7325\n",
      "Epoch 626/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3351 - mean_squared_error: 0.3351 - val_loss: 0.7238 - val_mean_squared_error: 0.7238\n",
      "Epoch 627/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3367 - mean_squared_error: 0.3367 - val_loss: 0.7321 - val_mean_squared_error: 0.7321\n",
      "Epoch 628/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3072 - mean_squared_error: 0.3072 - val_loss: 0.7206 - val_mean_squared_error: 0.7206\n",
      "Epoch 629/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3178 - mean_squared_error: 0.3178 - val_loss: 0.7784 - val_mean_squared_error: 0.7784\n",
      "Epoch 630/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3014 - mean_squared_error: 0.3014 - val_loss: 0.7205 - val_mean_squared_error: 0.7205\n",
      "Epoch 631/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.7087 - val_mean_squared_error: 0.7087\n",
      "Epoch 632/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3251 - mean_squared_error: 0.3251 - val_loss: 0.7232 - val_mean_squared_error: 0.7232\n",
      "Epoch 633/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3340 - mean_squared_error: 0.3340 - val_loss: 0.7174 - val_mean_squared_error: 0.7174\n",
      "Epoch 634/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3388 - mean_squared_error: 0.3388 - val_loss: 0.7374 - val_mean_squared_error: 0.7374\n",
      "Epoch 635/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.7318 - val_mean_squared_error: 0.7318\n",
      "Epoch 636/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3236 - mean_squared_error: 0.3236 - val_loss: 0.7490 - val_mean_squared_error: 0.7490\n",
      "Epoch 637/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3366 - mean_squared_error: 0.3366 - val_loss: 0.7151 - val_mean_squared_error: 0.7151\n",
      "Epoch 638/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3429 - mean_squared_error: 0.3429 - val_loss: 0.7085 - val_mean_squared_error: 0.7085\n",
      "Epoch 639/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3632 - mean_squared_error: 0.3632 - val_loss: 0.6966 - val_mean_squared_error: 0.6966\n",
      "Epoch 640/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3427 - mean_squared_error: 0.3427 - val_loss: 0.7045 - val_mean_squared_error: 0.7045\n",
      "Epoch 641/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.7121 - val_mean_squared_error: 0.7121\n",
      "Epoch 642/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3342 - mean_squared_error: 0.3342 - val_loss: 0.7079 - val_mean_squared_error: 0.7079\n",
      "Epoch 643/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3345 - mean_squared_error: 0.3345 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 644/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3191 - mean_squared_error: 0.3191 - val_loss: 0.7122 - val_mean_squared_error: 0.7122\n",
      "Epoch 645/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3158 - mean_squared_error: 0.3158 - val_loss: 0.7420 - val_mean_squared_error: 0.7420\n",
      "Epoch 646/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3341 - mean_squared_error: 0.3341 - val_loss: 0.7349 - val_mean_squared_error: 0.7349\n",
      "Epoch 647/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3074 - mean_squared_error: 0.3074 - val_loss: 0.7212 - val_mean_squared_error: 0.7212\n",
      "Epoch 648/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3103 - mean_squared_error: 0.3103 - val_loss: 0.7358 - val_mean_squared_error: 0.7358\n",
      "Epoch 649/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3379 - mean_squared_error: 0.3379 - val_loss: 0.7140 - val_mean_squared_error: 0.7140\n",
      "Epoch 650/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3115 - mean_squared_error: 0.3115 - val_loss: 0.7220 - val_mean_squared_error: 0.7220\n",
      "Epoch 651/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3179 - mean_squared_error: 0.3179 - val_loss: 0.7477 - val_mean_squared_error: 0.7477\n",
      "Epoch 652/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3256 - mean_squared_error: 0.3256 - val_loss: 0.7655 - val_mean_squared_error: 0.7655\n",
      "Epoch 653/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3457 - mean_squared_error: 0.3457 - val_loss: 0.7672 - val_mean_squared_error: 0.7672\n",
      "Epoch 654/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3417 - mean_squared_error: 0.3417 - val_loss: 0.7411 - val_mean_squared_error: 0.7411\n",
      "Epoch 655/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3206 - mean_squared_error: 0.3206 - val_loss: 0.7659 - val_mean_squared_error: 0.7659\n",
      "Epoch 656/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3613 - mean_squared_error: 0.3613 - val_loss: 0.7474 - val_mean_squared_error: 0.7474\n",
      "Epoch 657/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2941 - mean_squared_error: 0.2941 - val_loss: 0.7754 - val_mean_squared_error: 0.7754\n",
      "Epoch 658/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3342 - mean_squared_error: 0.3342 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
      "Epoch 659/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3252 - mean_squared_error: 0.3252 - val_loss: 0.7322 - val_mean_squared_error: 0.7322\n",
      "Epoch 660/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3702 - mean_squared_error: 0.3702 - val_loss: 0.7304 - val_mean_squared_error: 0.7304\n",
      "Epoch 661/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3211 - mean_squared_error: 0.3211 - val_loss: 0.7319 - val_mean_squared_error: 0.7319\n",
      "Epoch 662/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3393 - mean_squared_error: 0.3393 - val_loss: 0.7529 - val_mean_squared_error: 0.7529\n",
      "Epoch 663/1000\n",
      "1068/1068 [==============================] - 0s 111us/step - loss: 0.3256 - mean_squared_error: 0.3256 - val_loss: 0.7086 - val_mean_squared_error: 0.7086\n",
      "Epoch 664/1000\n",
      "1068/1068 [==============================] - 0s 114us/step - loss: 0.3459 - mean_squared_error: 0.3459 - val_loss: 0.7334 - val_mean_squared_error: 0.7334\n",
      "Epoch 665/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3145 - mean_squared_error: 0.3145 - val_loss: 0.7472 - val_mean_squared_error: 0.7472\n",
      "Epoch 666/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3756 - mean_squared_error: 0.3756 - val_loss: 0.7145 - val_mean_squared_error: 0.7145\n",
      "Epoch 667/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3488 - mean_squared_error: 0.3488 - val_loss: 0.7169 - val_mean_squared_error: 0.7169\n",
      "Epoch 668/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3386 - mean_squared_error: 0.3386 - val_loss: 0.7198 - val_mean_squared_error: 0.7198\n",
      "Epoch 669/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3398 - mean_squared_error: 0.3398 - val_loss: 0.7039 - val_mean_squared_error: 0.7039\n",
      "Epoch 670/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.2965 - mean_squared_error: 0.2965 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 671/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.2931 - mean_squared_error: 0.2931 - val_loss: 0.7180 - val_mean_squared_error: 0.7180\n",
      "Epoch 672/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3457 - mean_squared_error: 0.3457 - val_loss: 0.7245 - val_mean_squared_error: 0.7245\n",
      "Epoch 673/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3630 - mean_squared_error: 0.3630 - val_loss: 0.7654 - val_mean_squared_error: 0.7654\n",
      "Epoch 674/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3306 - mean_squared_error: 0.3306 - val_loss: 0.7113 - val_mean_squared_error: 0.7113\n",
      "Epoch 675/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3251 - mean_squared_error: 0.3251 - val_loss: 0.7165 - val_mean_squared_error: 0.7165\n",
      "Epoch 676/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3376 - mean_squared_error: 0.3376 - val_loss: 0.7470 - val_mean_squared_error: 0.7470\n",
      "Epoch 677/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3229 - mean_squared_error: 0.3229 - val_loss: 0.7217 - val_mean_squared_error: 0.7217\n",
      "Epoch 678/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3273 - mean_squared_error: 0.3273 - val_loss: 0.7015 - val_mean_squared_error: 0.7015\n",
      "Epoch 679/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3436 - mean_squared_error: 0.3436 - val_loss: 0.7033 - val_mean_squared_error: 0.7033\n",
      "Epoch 680/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3842 - mean_squared_error: 0.3842 - val_loss: 0.6948 - val_mean_squared_error: 0.6948\n",
      "Epoch 681/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3185 - mean_squared_error: 0.3185 - val_loss: 0.7200 - val_mean_squared_error: 0.7200\n",
      "Epoch 682/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3416 - mean_squared_error: 0.3416 - val_loss: 0.7129 - val_mean_squared_error: 0.7129\n",
      "Epoch 683/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3381 - mean_squared_error: 0.3381 - val_loss: 0.7346 - val_mean_squared_error: 0.7346\n",
      "Epoch 684/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3457 - mean_squared_error: 0.3457 - val_loss: 0.6928 - val_mean_squared_error: 0.6928\n",
      "Epoch 685/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3425 - mean_squared_error: 0.3425 - val_loss: 0.7161 - val_mean_squared_error: 0.7161\n",
      "Epoch 686/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3574 - mean_squared_error: 0.3574 - val_loss: 0.7569 - val_mean_squared_error: 0.7569\n",
      "Epoch 687/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3404 - mean_squared_error: 0.3404 - val_loss: 0.7207 - val_mean_squared_error: 0.7207\n",
      "Epoch 688/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.7121 - val_mean_squared_error: 0.7121\n",
      "Epoch 689/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3169 - mean_squared_error: 0.3169 - val_loss: 0.7191 - val_mean_squared_error: 0.7191\n",
      "Epoch 690/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3677 - mean_squared_error: 0.3677 - val_loss: 0.7048 - val_mean_squared_error: 0.7048\n",
      "Epoch 691/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3708 - mean_squared_error: 0.3708 - val_loss: 0.7391 - val_mean_squared_error: 0.7391\n",
      "Epoch 692/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.2958 - mean_squared_error: 0.2958 - val_loss: 0.7321 - val_mean_squared_error: 0.7321\n",
      "Epoch 693/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3508 - mean_squared_error: 0.3508 - val_loss: 0.7709 - val_mean_squared_error: 0.7709\n",
      "Epoch 694/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3597 - mean_squared_error: 0.3597 - val_loss: 0.7390 - val_mean_squared_error: 0.7390\n",
      "Epoch 695/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.2991 - mean_squared_error: 0.2991 - val_loss: 0.7396 - val_mean_squared_error: 0.7396\n",
      "Epoch 696/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3495 - mean_squared_error: 0.3495 - val_loss: 0.7461 - val_mean_squared_error: 0.7461\n",
      "Epoch 697/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3703 - mean_squared_error: 0.3703 - val_loss: 0.7525 - val_mean_squared_error: 0.7525\n",
      "Epoch 698/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3155 - mean_squared_error: 0.3155 - val_loss: 0.7353 - val_mean_squared_error: 0.7353\n",
      "Epoch 699/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3481 - mean_squared_error: 0.3481 - val_loss: 0.7316 - val_mean_squared_error: 0.7316\n",
      "Epoch 700/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3498 - mean_squared_error: 0.3498 - val_loss: 0.7265 - val_mean_squared_error: 0.7265\n",
      "Epoch 701/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3480 - mean_squared_error: 0.3480 - val_loss: 0.7192 - val_mean_squared_error: 0.7192\n",
      "Epoch 702/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3000 - mean_squared_error: 0.3000 - val_loss: 0.7147 - val_mean_squared_error: 0.7147\n",
      "Epoch 703/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3365 - mean_squared_error: 0.3365 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
      "Epoch 704/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.2988 - mean_squared_error: 0.2988 - val_loss: 0.7410 - val_mean_squared_error: 0.7410\n",
      "Epoch 705/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.7722 - val_mean_squared_error: 0.7722\n",
      "Epoch 706/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3342 - mean_squared_error: 0.3342 - val_loss: 0.7381 - val_mean_squared_error: 0.7381\n",
      "Epoch 707/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
      "Epoch 708/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3442 - mean_squared_error: 0.3442 - val_loss: 0.7153 - val_mean_squared_error: 0.7153\n",
      "Epoch 709/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3175 - mean_squared_error: 0.3175 - val_loss: 0.7791 - val_mean_squared_error: 0.7791\n",
      "Epoch 710/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3241 - mean_squared_error: 0.3241 - val_loss: 0.7126 - val_mean_squared_error: 0.7126\n",
      "Epoch 711/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3478 - mean_squared_error: 0.3478 - val_loss: 0.7641 - val_mean_squared_error: 0.7641\n",
      "Epoch 712/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.7359 - val_mean_squared_error: 0.7359\n",
      "Epoch 713/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3658 - mean_squared_error: 0.3658 - val_loss: 0.7301 - val_mean_squared_error: 0.7301\n",
      "Epoch 714/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3472 - mean_squared_error: 0.3472 - val_loss: 0.7120 - val_mean_squared_error: 0.7120\n",
      "Epoch 715/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3367 - mean_squared_error: 0.3367 - val_loss: 0.7413 - val_mean_squared_error: 0.7413\n",
      "Epoch 716/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3318 - mean_squared_error: 0.3318 - val_loss: 0.7284 - val_mean_squared_error: 0.7284\n",
      "Epoch 717/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2954 - mean_squared_error: 0.2954 - val_loss: 0.7269 - val_mean_squared_error: 0.7269\n",
      "Epoch 718/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3467 - mean_squared_error: 0.3467 - val_loss: 0.7620 - val_mean_squared_error: 0.7620\n",
      "Epoch 719/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3315 - mean_squared_error: 0.3315 - val_loss: 0.7042 - val_mean_squared_error: 0.7042\n",
      "Epoch 720/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3272 - mean_squared_error: 0.3272 - val_loss: 0.7452 - val_mean_squared_error: 0.7452\n",
      "Epoch 721/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3366 - mean_squared_error: 0.3366 - val_loss: 0.7192 - val_mean_squared_error: 0.7192\n",
      "Epoch 722/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3558 - mean_squared_error: 0.3558 - val_loss: 0.7714 - val_mean_squared_error: 0.7714\n",
      "Epoch 723/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3535 - mean_squared_error: 0.3535 - val_loss: 0.7317 - val_mean_squared_error: 0.7317\n",
      "Epoch 724/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3332 - mean_squared_error: 0.3332 - val_loss: 0.7130 - val_mean_squared_error: 0.7130\n",
      "Epoch 725/1000\n",
      "1068/1068 [==============================] - 0s 92us/step - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.7259 - val_mean_squared_error: 0.7259\n",
      "Epoch 726/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3304 - mean_squared_error: 0.3304 - val_loss: 0.7494 - val_mean_squared_error: 0.7494\n",
      "Epoch 727/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3469 - mean_squared_error: 0.3469 - val_loss: 0.7424 - val_mean_squared_error: 0.7424\n",
      "Epoch 728/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3452 - mean_squared_error: 0.3452 - val_loss: 0.7429 - val_mean_squared_error: 0.7429\n",
      "Epoch 729/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3666 - mean_squared_error: 0.3666 - val_loss: 0.7305 - val_mean_squared_error: 0.7305\n",
      "Epoch 730/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.7322 - val_mean_squared_error: 0.7322\n",
      "Epoch 731/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3596 - mean_squared_error: 0.3596 - val_loss: 0.7304 - val_mean_squared_error: 0.7304\n",
      "Epoch 732/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3155 - mean_squared_error: 0.3155 - val_loss: 0.7468 - val_mean_squared_error: 0.7468\n",
      "Epoch 733/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3466 - mean_squared_error: 0.3466 - val_loss: 0.7380 - val_mean_squared_error: 0.7380\n",
      "Epoch 734/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.7192 - val_mean_squared_error: 0.7192\n",
      "Epoch 735/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3670 - mean_squared_error: 0.3670 - val_loss: 0.7484 - val_mean_squared_error: 0.7484\n",
      "Epoch 736/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3413 - mean_squared_error: 0.3413 - val_loss: 0.7335 - val_mean_squared_error: 0.7335\n",
      "Epoch 737/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3027 - mean_squared_error: 0.3027 - val_loss: 0.7381 - val_mean_squared_error: 0.7381\n",
      "Epoch 738/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3337 - mean_squared_error: 0.3337 - val_loss: 0.7197 - val_mean_squared_error: 0.7197\n",
      "Epoch 739/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3269 - mean_squared_error: 0.3269 - val_loss: 0.7793 - val_mean_squared_error: 0.7793\n",
      "Epoch 740/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3447 - mean_squared_error: 0.3447 - val_loss: 0.7194 - val_mean_squared_error: 0.7194\n",
      "Epoch 741/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.2965 - mean_squared_error: 0.2965 - val_loss: 0.7193 - val_mean_squared_error: 0.7193\n",
      "Epoch 742/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3408 - mean_squared_error: 0.3408 - val_loss: 0.7504 - val_mean_squared_error: 0.7504\n",
      "Epoch 743/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3557 - mean_squared_error: 0.3557 - val_loss: 0.7541 - val_mean_squared_error: 0.7541\n",
      "Epoch 744/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3515 - mean_squared_error: 0.3515 - val_loss: 0.7169 - val_mean_squared_error: 0.7169\n",
      "Epoch 745/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3325 - mean_squared_error: 0.3325 - val_loss: 0.7474 - val_mean_squared_error: 0.7474\n",
      "Epoch 746/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3189 - mean_squared_error: 0.3189 - val_loss: 0.7171 - val_mean_squared_error: 0.7171\n",
      "Epoch 747/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3327 - mean_squared_error: 0.3327 - val_loss: 0.7389 - val_mean_squared_error: 0.7389\n",
      "Epoch 748/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3512 - mean_squared_error: 0.3512 - val_loss: 0.7113 - val_mean_squared_error: 0.7113\n",
      "Epoch 749/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3309 - mean_squared_error: 0.3309 - val_loss: 0.7582 - val_mean_squared_error: 0.7582\n",
      "Epoch 750/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.7224 - val_mean_squared_error: 0.7224\n",
      "Epoch 751/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3451 - mean_squared_error: 0.3451 - val_loss: 0.7261 - val_mean_squared_error: 0.7261\n",
      "Epoch 752/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3471 - mean_squared_error: 0.3471 - val_loss: 0.7363 - val_mean_squared_error: 0.7363\n",
      "Epoch 753/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3553 - mean_squared_error: 0.3553 - val_loss: 0.7085 - val_mean_squared_error: 0.7085\n",
      "Epoch 754/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3530 - mean_squared_error: 0.3530 - val_loss: 0.7235 - val_mean_squared_error: 0.7235\n",
      "Epoch 755/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3084 - mean_squared_error: 0.3084 - val_loss: 0.6963 - val_mean_squared_error: 0.6963\n",
      "Epoch 756/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3181 - mean_squared_error: 0.3181 - val_loss: 0.7132 - val_mean_squared_error: 0.7132\n",
      "Epoch 757/1000\n",
      "1068/1068 [==============================] - 0s 105us/step - loss: 0.3423 - mean_squared_error: 0.3423 - val_loss: 0.7372 - val_mean_squared_error: 0.7372\n",
      "Epoch 758/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.7287 - val_mean_squared_error: 0.7287\n",
      "Epoch 759/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3158 - mean_squared_error: 0.3158 - val_loss: 0.7377 - val_mean_squared_error: 0.7377\n",
      "Epoch 760/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3145 - mean_squared_error: 0.3145 - val_loss: 0.7436 - val_mean_squared_error: 0.7436\n",
      "Epoch 761/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.7413 - val_mean_squared_error: 0.7413\n",
      "Epoch 762/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3713 - mean_squared_error: 0.3713 - val_loss: 0.7229 - val_mean_squared_error: 0.7229\n",
      "Epoch 763/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3176 - mean_squared_error: 0.3176 - val_loss: 0.7558 - val_mean_squared_error: 0.7558\n",
      "Epoch 764/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3025 - mean_squared_error: 0.3025 - val_loss: 0.7343 - val_mean_squared_error: 0.7343\n",
      "Epoch 765/1000\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3365 - mean_squared_error: 0.33 - 0s 113us/step - loss: 0.3124 - mean_squared_error: 0.3124 - val_loss: 0.7666 - val_mean_squared_error: 0.7666\n",
      "Epoch 766/1000\n",
      "1068/1068 [==============================] - 0s 117us/step - loss: 0.3277 - mean_squared_error: 0.3277 - val_loss: 0.7354 - val_mean_squared_error: 0.7354\n",
      "Epoch 767/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3343 - mean_squared_error: 0.3343 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 768/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.7296 - val_mean_squared_error: 0.7296\n",
      "Epoch 769/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.7251 - val_mean_squared_error: 0.7251\n",
      "Epoch 770/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3420 - mean_squared_error: 0.3420 - val_loss: 0.7444 - val_mean_squared_error: 0.7444\n",
      "Epoch 771/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3476 - mean_squared_error: 0.3476 - val_loss: 0.7232 - val_mean_squared_error: 0.7232\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3656 - mean_squared_error: 0.3656 - val_loss: 0.7174 - val_mean_squared_error: 0.7174\n",
      "Epoch 773/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.7335 - val_mean_squared_error: 0.7335\n",
      "Epoch 774/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3507 - mean_squared_error: 0.3507 - val_loss: 0.7085 - val_mean_squared_error: 0.7085\n",
      "Epoch 775/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3681 - mean_squared_error: 0.3681 - val_loss: 0.7124 - val_mean_squared_error: 0.7124\n",
      "Epoch 776/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3488 - mean_squared_error: 0.3488 - val_loss: 0.7324 - val_mean_squared_error: 0.7324\n",
      "Epoch 777/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3609 - mean_squared_error: 0.3609 - val_loss: 0.7311 - val_mean_squared_error: 0.7311\n",
      "Epoch 778/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3479 - mean_squared_error: 0.3479 - val_loss: 0.7125 - val_mean_squared_error: 0.7125\n",
      "Epoch 779/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3113 - mean_squared_error: 0.3113 - val_loss: 0.7551 - val_mean_squared_error: 0.7551\n",
      "Epoch 780/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.7282 - val_mean_squared_error: 0.7282\n",
      "Epoch 781/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3591 - mean_squared_error: 0.3591 - val_loss: 0.7348 - val_mean_squared_error: 0.7348\n",
      "Epoch 782/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3333 - mean_squared_error: 0.3333 - val_loss: 0.7293 - val_mean_squared_error: 0.7293\n",
      "Epoch 783/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3097 - mean_squared_error: 0.3097 - val_loss: 0.7311 - val_mean_squared_error: 0.7311\n",
      "Epoch 784/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3427 - mean_squared_error: 0.3427 - val_loss: 0.7351 - val_mean_squared_error: 0.7351\n",
      "Epoch 785/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.2983 - mean_squared_error: 0.2983 - val_loss: 0.7248 - val_mean_squared_error: 0.7248\n",
      "Epoch 786/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3166 - mean_squared_error: 0.3166 - val_loss: 0.7741 - val_mean_squared_error: 0.7741\n",
      "Epoch 787/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3506 - mean_squared_error: 0.3506 - val_loss: 0.7554 - val_mean_squared_error: 0.7554\n",
      "Epoch 788/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.7430 - val_mean_squared_error: 0.7430\n",
      "Epoch 789/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3047 - mean_squared_error: 0.3047 - val_loss: 0.7314 - val_mean_squared_error: 0.7314\n",
      "Epoch 790/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3356 - mean_squared_error: 0.3356 - val_loss: 0.7480 - val_mean_squared_error: 0.7480\n",
      "Epoch 791/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.7155 - val_mean_squared_error: 0.7155\n",
      "Epoch 792/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3090 - mean_squared_error: 0.3090 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 793/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3910 - mean_squared_error: 0.3910 - val_loss: 0.7277 - val_mean_squared_error: 0.7277\n",
      "Epoch 794/1000\n",
      "1068/1068 [==============================] - 0s 109us/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.7422 - val_mean_squared_error: 0.7422\n",
      "Epoch 795/1000\n",
      "1068/1068 [==============================] - 0s 118us/step - loss: 0.3404 - mean_squared_error: 0.3404 - val_loss: 0.7328 - val_mean_squared_error: 0.7328\n",
      "Epoch 796/1000\n",
      "1068/1068 [==============================] - 0s 133us/step - loss: 0.3623 - mean_squared_error: 0.3623 - val_loss: 0.7235 - val_mean_squared_error: 0.7235\n",
      "Epoch 797/1000\n",
      "1068/1068 [==============================] - 0s 124us/step - loss: 0.3532 - mean_squared_error: 0.3532 - val_loss: 0.7228 - val_mean_squared_error: 0.7228\n",
      "Epoch 798/1000\n",
      "1068/1068 [==============================] - 0s 140us/step - loss: 0.3560 - mean_squared_error: 0.3560 - val_loss: 0.7276 - val_mean_squared_error: 0.7276\n",
      "Epoch 799/1000\n",
      "1068/1068 [==============================] - 0s 116us/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.7191 - val_mean_squared_error: 0.7191\n",
      "Epoch 800/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.3302 - mean_squared_error: 0.3302 - val_loss: 0.7384 - val_mean_squared_error: 0.7384\n",
      "Epoch 801/1000\n",
      "1068/1068 [==============================] - 0s 108us/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.7224 - val_mean_squared_error: 0.7224\n",
      "Epoch 802/1000\n",
      "1068/1068 [==============================] - 0s 116us/step - loss: 0.3239 - mean_squared_error: 0.3239 - val_loss: 0.7175 - val_mean_squared_error: 0.7175\n",
      "Epoch 803/1000\n",
      "1068/1068 [==============================] - 0s 110us/step - loss: 0.3385 - mean_squared_error: 0.3385 - val_loss: 0.7471 - val_mean_squared_error: 0.7471\n",
      "Epoch 804/1000\n",
      "1068/1068 [==============================] - 0s 144us/step - loss: 0.3171 - mean_squared_error: 0.3171 - val_loss: 0.7131 - val_mean_squared_error: 0.7131\n",
      "Epoch 805/1000\n",
      "1068/1068 [==============================] - 0s 112us/step - loss: 0.3433 - mean_squared_error: 0.3433 - val_loss: 0.7192 - val_mean_squared_error: 0.7192\n",
      "Epoch 806/1000\n",
      "1068/1068 [==============================] - 0s 118us/step - loss: 0.2998 - mean_squared_error: 0.2998 - val_loss: 0.7098 - val_mean_squared_error: 0.7098\n",
      "Epoch 807/1000\n",
      "1068/1068 [==============================] - ETA: 0s - loss: 0.3572 - mean_squared_error: 0.35 - 0s 108us/step - loss: 0.3441 - mean_squared_error: 0.3441 - val_loss: 0.7098 - val_mean_squared_error: 0.7098\n",
      "Epoch 808/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3707 - mean_squared_error: 0.3707 - val_loss: 0.7214 - val_mean_squared_error: 0.7214\n",
      "Epoch 809/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3181 - mean_squared_error: 0.3181 - val_loss: 0.7380 - val_mean_squared_error: 0.7380\n",
      "Epoch 810/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3351 - mean_squared_error: 0.3351 - val_loss: 0.7141 - val_mean_squared_error: 0.7141\n",
      "Epoch 811/1000\n",
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3117 - mean_squared_error: 0.3117 - val_loss: 0.7231 - val_mean_squared_error: 0.7231\n",
      "Epoch 812/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3808 - mean_squared_error: 0.3808 - val_loss: 0.7282 - val_mean_squared_error: 0.7282\n",
      "Epoch 813/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3705 - mean_squared_error: 0.3705 - val_loss: 0.7027 - val_mean_squared_error: 0.7027\n",
      "Epoch 814/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3414 - mean_squared_error: 0.3414 - val_loss: 0.7169 - val_mean_squared_error: 0.7169\n",
      "Epoch 815/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3345 - mean_squared_error: 0.3345 - val_loss: 0.7121 - val_mean_squared_error: 0.7121\n",
      "Epoch 816/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3208 - mean_squared_error: 0.3208 - val_loss: 0.7184 - val_mean_squared_error: 0.7184\n",
      "Epoch 817/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3207 - mean_squared_error: 0.3207 - val_loss: 0.7296 - val_mean_squared_error: 0.7296\n",
      "Epoch 818/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3345 - mean_squared_error: 0.3345 - val_loss: 0.7381 - val_mean_squared_error: 0.7381\n",
      "Epoch 819/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.2982 - mean_squared_error: 0.2982 - val_loss: 0.7198 - val_mean_squared_error: 0.7198\n",
      "Epoch 820/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 107us/step - loss: 0.3489 - mean_squared_error: 0.3489 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
      "Epoch 821/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3394 - mean_squared_error: 0.3394 - val_loss: 0.7174 - val_mean_squared_error: 0.7174\n",
      "Epoch 822/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3193 - mean_squared_error: 0.3193 - val_loss: 0.7306 - val_mean_squared_error: 0.7306\n",
      "Epoch 823/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3100 - mean_squared_error: 0.3100 - val_loss: 0.7394 - val_mean_squared_error: 0.7394\n",
      "Epoch 824/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3394 - mean_squared_error: 0.3394 - val_loss: 0.7179 - val_mean_squared_error: 0.7179\n",
      "Epoch 825/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3350 - mean_squared_error: 0.3350 - val_loss: 0.7478 - val_mean_squared_error: 0.7478\n",
      "Epoch 826/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3320 - mean_squared_error: 0.3320 - val_loss: 0.7564 - val_mean_squared_error: 0.7564\n",
      "Epoch 827/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3018 - mean_squared_error: 0.3018 - val_loss: 0.7470 - val_mean_squared_error: 0.7470\n",
      "Epoch 828/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3432 - mean_squared_error: 0.3432 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 829/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
      "Epoch 830/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3363 - mean_squared_error: 0.3363 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
      "Epoch 831/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3788 - mean_squared_error: 0.3788 - val_loss: 0.7583 - val_mean_squared_error: 0.7583\n",
      "Epoch 832/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3640 - mean_squared_error: 0.3640 - val_loss: 0.7274 - val_mean_squared_error: 0.7274\n",
      "Epoch 833/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2915 - mean_squared_error: 0.2915 - val_loss: 0.7542 - val_mean_squared_error: 0.7542\n",
      "Epoch 834/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3359 - mean_squared_error: 0.3359 - val_loss: 0.7551 - val_mean_squared_error: 0.7551\n",
      "Epoch 835/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3323 - mean_squared_error: 0.3323 - val_loss: 0.7141 - val_mean_squared_error: 0.7141\n",
      "Epoch 836/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3074 - mean_squared_error: 0.3074 - val_loss: 0.7417 - val_mean_squared_error: 0.7417\n",
      "Epoch 837/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2900 - mean_squared_error: 0.2900 - val_loss: 0.7428 - val_mean_squared_error: 0.7428\n",
      "Epoch 838/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3364 - mean_squared_error: 0.3364 - val_loss: 0.7377 - val_mean_squared_error: 0.7377\n",
      "Epoch 839/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3732 - mean_squared_error: 0.3732 - val_loss: 0.7854 - val_mean_squared_error: 0.7854\n",
      "Epoch 840/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3393 - mean_squared_error: 0.3393 - val_loss: 0.7379 - val_mean_squared_error: 0.7379\n",
      "Epoch 841/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3115 - mean_squared_error: 0.3115 - val_loss: 0.7076 - val_mean_squared_error: 0.7076\n",
      "Epoch 842/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3318 - mean_squared_error: 0.3318 - val_loss: 0.7606 - val_mean_squared_error: 0.7606\n",
      "Epoch 843/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3289 - mean_squared_error: 0.3289 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
      "Epoch 844/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3421 - mean_squared_error: 0.3421 - val_loss: 0.7309 - val_mean_squared_error: 0.7309\n",
      "Epoch 845/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3334 - mean_squared_error: 0.3334 - val_loss: 0.7412 - val_mean_squared_error: 0.7412\n",
      "Epoch 846/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3296 - mean_squared_error: 0.3296 - val_loss: 0.7252 - val_mean_squared_error: 0.7252\n",
      "Epoch 847/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3508 - mean_squared_error: 0.3508 - val_loss: 0.7354 - val_mean_squared_error: 0.7354\n",
      "Epoch 848/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3266 - mean_squared_error: 0.3266 - val_loss: 0.7485 - val_mean_squared_error: 0.7485\n",
      "Epoch 849/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3611 - mean_squared_error: 0.3611 - val_loss: 0.7252 - val_mean_squared_error: 0.7252\n",
      "Epoch 850/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3259 - mean_squared_error: 0.3259 - val_loss: 0.7348 - val_mean_squared_error: 0.7348\n",
      "Epoch 851/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3063 - mean_squared_error: 0.3063 - val_loss: 0.7438 - val_mean_squared_error: 0.7438\n",
      "Epoch 852/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3238 - mean_squared_error: 0.3238 - val_loss: 0.7234 - val_mean_squared_error: 0.7234\n",
      "Epoch 853/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3367 - mean_squared_error: 0.3367 - val_loss: 0.7438 - val_mean_squared_error: 0.7438\n",
      "Epoch 854/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.7619 - val_mean_squared_error: 0.7619\n",
      "Epoch 855/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3463 - mean_squared_error: 0.3463 - val_loss: 0.7276 - val_mean_squared_error: 0.7276\n",
      "Epoch 856/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.7153 - val_mean_squared_error: 0.7153\n",
      "Epoch 857/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3689 - mean_squared_error: 0.3689 - val_loss: 0.7227 - val_mean_squared_error: 0.7227\n",
      "Epoch 858/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3587 - mean_squared_error: 0.3587 - val_loss: 0.7570 - val_mean_squared_error: 0.7570\n",
      "Epoch 859/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3328 - mean_squared_error: 0.3328 - val_loss: 0.7269 - val_mean_squared_error: 0.7269\n",
      "Epoch 860/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3054 - mean_squared_error: 0.3054 - val_loss: 0.7486 - val_mean_squared_error: 0.7486\n",
      "Epoch 861/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3121 - mean_squared_error: 0.3121 - val_loss: 0.7406 - val_mean_squared_error: 0.7406\n",
      "Epoch 862/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3485 - mean_squared_error: 0.3485 - val_loss: 0.7027 - val_mean_squared_error: 0.7027\n",
      "Epoch 863/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.7262 - val_mean_squared_error: 0.7262\n",
      "Epoch 864/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3664 - mean_squared_error: 0.3664 - val_loss: 0.7131 - val_mean_squared_error: 0.7131\n",
      "Epoch 865/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3148 - mean_squared_error: 0.3148 - val_loss: 0.7316 - val_mean_squared_error: 0.7316\n",
      "Epoch 866/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.2902 - mean_squared_error: 0.2902 - val_loss: 0.7201 - val_mean_squared_error: 0.7201\n",
      "Epoch 867/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3118 - mean_squared_error: 0.3118 - val_loss: 0.7156 - val_mean_squared_error: 0.7156\n",
      "Epoch 868/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3317 - mean_squared_error: 0.3317 - val_loss: 0.7601 - val_mean_squared_error: 0.7601\n",
      "Epoch 869/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3398 - mean_squared_error: 0.3398 - val_loss: 0.7360 - val_mean_squared_error: 0.7360\n",
      "Epoch 870/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3117 - mean_squared_error: 0.3117 - val_loss: 0.7495 - val_mean_squared_error: 0.7495\n",
      "Epoch 871/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3366 - mean_squared_error: 0.3366 - val_loss: 0.7497 - val_mean_squared_error: 0.7497\n",
      "Epoch 872/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3257 - mean_squared_error: 0.3257 - val_loss: 0.7437 - val_mean_squared_error: 0.7437\n",
      "Epoch 873/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3650 - mean_squared_error: 0.3650 - val_loss: 0.7315 - val_mean_squared_error: 0.7315\n",
      "Epoch 874/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3573 - mean_squared_error: 0.3573 - val_loss: 0.7185 - val_mean_squared_error: 0.7185\n",
      "Epoch 875/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3485 - mean_squared_error: 0.3485 - val_loss: 0.7166 - val_mean_squared_error: 0.7166\n",
      "Epoch 876/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3450 - mean_squared_error: 0.3450 - val_loss: 0.7608 - val_mean_squared_error: 0.7608\n",
      "Epoch 877/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3034 - mean_squared_error: 0.3034 - val_loss: 0.7344 - val_mean_squared_error: 0.7344\n",
      "Epoch 878/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3310 - mean_squared_error: 0.3310 - val_loss: 0.7307 - val_mean_squared_error: 0.7307\n",
      "Epoch 879/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3322 - mean_squared_error: 0.3322 - val_loss: 0.7430 - val_mean_squared_error: 0.7430\n",
      "Epoch 880/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3289 - mean_squared_error: 0.3289 - val_loss: 0.7186 - val_mean_squared_error: 0.7186\n",
      "Epoch 881/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.2902 - mean_squared_error: 0.2902 - val_loss: 0.7458 - val_mean_squared_error: 0.7458\n",
      "Epoch 882/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3616 - mean_squared_error: 0.3616 - val_loss: 0.7544 - val_mean_squared_error: 0.7544\n",
      "Epoch 883/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3215 - mean_squared_error: 0.3215 - val_loss: 0.7102 - val_mean_squared_error: 0.7102\n",
      "Epoch 884/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.7659 - val_mean_squared_error: 0.7659\n",
      "Epoch 885/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3084 - mean_squared_error: 0.3084 - val_loss: 0.7142 - val_mean_squared_error: 0.7142\n",
      "Epoch 886/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.7196 - val_mean_squared_error: 0.7196\n",
      "Epoch 887/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3271 - mean_squared_error: 0.3271 - val_loss: 0.7234 - val_mean_squared_error: 0.7234\n",
      "Epoch 888/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.2886 - mean_squared_error: 0.2886 - val_loss: 0.7200 - val_mean_squared_error: 0.7200\n",
      "Epoch 889/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.7287 - val_mean_squared_error: 0.7287\n",
      "Epoch 890/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3146 - mean_squared_error: 0.3146 - val_loss: 0.7290 - val_mean_squared_error: 0.7290\n",
      "Epoch 891/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3375 - mean_squared_error: 0.3375 - val_loss: 0.7357 - val_mean_squared_error: 0.7357\n",
      "Epoch 892/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3471 - mean_squared_error: 0.3471 - val_loss: 0.7445 - val_mean_squared_error: 0.7445\n",
      "Epoch 893/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3429 - mean_squared_error: 0.3429 - val_loss: 0.7145 - val_mean_squared_error: 0.7145\n",
      "Epoch 894/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3264 - mean_squared_error: 0.3264 - val_loss: 0.7280 - val_mean_squared_error: 0.7280\n",
      "Epoch 895/1000\n",
      "1068/1068 [==============================] - 0s 120us/step - loss: 0.3306 - mean_squared_error: 0.3306 - val_loss: 0.7516 - val_mean_squared_error: 0.7516\n",
      "Epoch 896/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3614 - mean_squared_error: 0.3614 - val_loss: 0.7053 - val_mean_squared_error: 0.7053\n",
      "Epoch 897/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3494 - mean_squared_error: 0.3494 - val_loss: 0.7144 - val_mean_squared_error: 0.7144\n",
      "Epoch 898/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.7639 - val_mean_squared_error: 0.7639\n",
      "Epoch 899/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3389 - mean_squared_error: 0.3389 - val_loss: 0.7577 - val_mean_squared_error: 0.7577\n",
      "Epoch 900/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3056 - mean_squared_error: 0.3056 - val_loss: 0.7121 - val_mean_squared_error: 0.7121\n",
      "Epoch 901/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3389 - mean_squared_error: 0.3389 - val_loss: 0.7216 - val_mean_squared_error: 0.7216\n",
      "Epoch 902/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3113 - mean_squared_error: 0.3113 - val_loss: 0.7288 - val_mean_squared_error: 0.7288\n",
      "Epoch 903/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3009 - mean_squared_error: 0.3009 - val_loss: 0.7101 - val_mean_squared_error: 0.7101\n",
      "Epoch 904/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3520 - mean_squared_error: 0.3520 - val_loss: 0.7148 - val_mean_squared_error: 0.7148\n",
      "Epoch 905/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3114 - mean_squared_error: 0.3114 - val_loss: 0.7264 - val_mean_squared_error: 0.7264\n",
      "Epoch 906/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.7268 - val_mean_squared_error: 0.7268\n",
      "Epoch 907/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3065 - mean_squared_error: 0.3065 - val_loss: 0.7069 - val_mean_squared_error: 0.7069\n",
      "Epoch 908/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3501 - mean_squared_error: 0.3501 - val_loss: 0.7054 - val_mean_squared_error: 0.7054\n",
      "Epoch 909/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3205 - mean_squared_error: 0.3205 - val_loss: 0.7376 - val_mean_squared_error: 0.7376\n",
      "Epoch 910/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.7416 - val_mean_squared_error: 0.7416\n",
      "Epoch 911/1000\n",
      "1068/1068 [==============================] - 0s 133us/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.7243 - val_mean_squared_error: 0.7243\n",
      "Epoch 912/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3390 - mean_squared_error: 0.3390 - val_loss: 0.7245 - val_mean_squared_error: 0.7245\n",
      "Epoch 913/1000\n",
      "1068/1068 [==============================] - 0s 113us/step - loss: 0.3263 - mean_squared_error: 0.3263 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n",
      "Epoch 914/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3231 - mean_squared_error: 0.3231 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 915/1000\n",
      "1068/1068 [==============================] - 0s 134us/step - loss: 0.3252 - mean_squared_error: 0.3252 - val_loss: 0.7222 - val_mean_squared_error: 0.7222\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 121us/step - loss: 0.3238 - mean_squared_error: 0.3238 - val_loss: 0.7728 - val_mean_squared_error: 0.7728\n",
      "Epoch 917/1000\n",
      "1068/1068 [==============================] - 0s 103us/step - loss: 0.3065 - mean_squared_error: 0.3065 - val_loss: 0.7249 - val_mean_squared_error: 0.7249\n",
      "Epoch 918/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3450 - mean_squared_error: 0.3450 - val_loss: 0.7173 - val_mean_squared_error: 0.7173\n",
      "Epoch 919/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.2979 - mean_squared_error: 0.2979 - val_loss: 0.7108 - val_mean_squared_error: 0.7108\n",
      "Epoch 920/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3703 - mean_squared_error: 0.3703 - val_loss: 0.7134 - val_mean_squared_error: 0.7134\n",
      "Epoch 921/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.2846 - mean_squared_error: 0.2846 - val_loss: 0.7494 - val_mean_squared_error: 0.7494\n",
      "Epoch 922/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3452 - mean_squared_error: 0.3452 - val_loss: 0.7188 - val_mean_squared_error: 0.7188\n",
      "Epoch 923/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.2974 - mean_squared_error: 0.2974 - val_loss: 0.7509 - val_mean_squared_error: 0.7509\n",
      "Epoch 924/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3267 - mean_squared_error: 0.3267 - val_loss: 0.7549 - val_mean_squared_error: 0.7549\n",
      "Epoch 925/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3208 - mean_squared_error: 0.3208 - val_loss: 0.7282 - val_mean_squared_error: 0.7282\n",
      "Epoch 926/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3209 - mean_squared_error: 0.3209 - val_loss: 0.7677 - val_mean_squared_error: 0.7677\n",
      "Epoch 927/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3007 - mean_squared_error: 0.3007 - val_loss: 0.7119 - val_mean_squared_error: 0.7119\n",
      "Epoch 928/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.2939 - mean_squared_error: 0.2939 - val_loss: 0.7066 - val_mean_squared_error: 0.7066\n",
      "Epoch 929/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3174 - mean_squared_error: 0.3174 - val_loss: 0.7743 - val_mean_squared_error: 0.7743\n",
      "Epoch 930/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3198 - mean_squared_error: 0.3198 - val_loss: 0.7448 - val_mean_squared_error: 0.7448\n",
      "Epoch 931/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.7116 - val_mean_squared_error: 0.7116\n",
      "Epoch 932/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3040 - mean_squared_error: 0.3040 - val_loss: 0.7347 - val_mean_squared_error: 0.7347\n",
      "Epoch 933/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3075 - mean_squared_error: 0.3075 - val_loss: 0.7485 - val_mean_squared_error: 0.7485\n",
      "Epoch 934/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3262 - mean_squared_error: 0.3262 - val_loss: 0.6995 - val_mean_squared_error: 0.6995\n",
      "Epoch 935/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3458 - mean_squared_error: 0.3458 - val_loss: 0.7323 - val_mean_squared_error: 0.7323\n",
      "Epoch 936/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3460 - mean_squared_error: 0.3460 - val_loss: 0.7275 - val_mean_squared_error: 0.7275\n",
      "Epoch 937/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.6970 - val_mean_squared_error: 0.6970\n",
      "Epoch 938/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3492 - mean_squared_error: 0.3492 - val_loss: 0.7077 - val_mean_squared_error: 0.7077\n",
      "Epoch 939/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3152 - mean_squared_error: 0.3152 - val_loss: 0.7279 - val_mean_squared_error: 0.7279\n",
      "Epoch 940/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3740 - mean_squared_error: 0.3740 - val_loss: 0.7210 - val_mean_squared_error: 0.7210\n",
      "Epoch 941/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3356 - mean_squared_error: 0.3356 - val_loss: 0.7595 - val_mean_squared_error: 0.7595\n",
      "Epoch 942/1000\n",
      "1068/1068 [==============================] - 0s 106us/step - loss: 0.3540 - mean_squared_error: 0.3540 - val_loss: 0.7365 - val_mean_squared_error: 0.7365\n",
      "Epoch 943/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3274 - mean_squared_error: 0.3274 - val_loss: 0.7242 - val_mean_squared_error: 0.7242\n",
      "Epoch 944/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3489 - mean_squared_error: 0.3489 - val_loss: 0.7233 - val_mean_squared_error: 0.7233\n",
      "Epoch 945/1000\n",
      "1068/1068 [==============================] - 0s 93us/step - loss: 0.3347 - mean_squared_error: 0.3347 - val_loss: 0.7236 - val_mean_squared_error: 0.7236\n",
      "Epoch 946/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3146 - mean_squared_error: 0.3146 - val_loss: 0.7215 - val_mean_squared_error: 0.7215\n",
      "Epoch 947/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3047 - mean_squared_error: 0.3047 - val_loss: 0.7170 - val_mean_squared_error: 0.7170\n",
      "Epoch 948/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3381 - mean_squared_error: 0.3381 - val_loss: 0.7460 - val_mean_squared_error: 0.7460\n",
      "Epoch 949/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.7128 - val_mean_squared_error: 0.7128\n",
      "Epoch 950/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3223 - mean_squared_error: 0.3223 - val_loss: 0.7348 - val_mean_squared_error: 0.7348\n",
      "Epoch 951/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3315 - mean_squared_error: 0.3315 - val_loss: 0.7265 - val_mean_squared_error: 0.7265\n",
      "Epoch 952/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3169 - mean_squared_error: 0.3169 - val_loss: 0.7653 - val_mean_squared_error: 0.7653\n",
      "Epoch 953/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3197 - mean_squared_error: 0.3197 - val_loss: 0.7575 - val_mean_squared_error: 0.7575\n",
      "Epoch 954/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3018 - mean_squared_error: 0.3018 - val_loss: 0.7136 - val_mean_squared_error: 0.7136\n",
      "Epoch 955/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3486 - mean_squared_error: 0.3486 - val_loss: 0.7071 - val_mean_squared_error: 0.7071\n",
      "Epoch 956/1000\n",
      "1068/1068 [==============================] - 0s 104us/step - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.6994 - val_mean_squared_error: 0.6994\n",
      "Epoch 957/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.2917 - mean_squared_error: 0.2917 - val_loss: 0.7224 - val_mean_squared_error: 0.7224\n",
      "Epoch 958/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3579 - mean_squared_error: 0.3579 - val_loss: 0.7238 - val_mean_squared_error: 0.7238\n",
      "Epoch 959/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3033 - mean_squared_error: 0.3033 - val_loss: 0.7620 - val_mean_squared_error: 0.7620\n",
      "Epoch 960/1000\n",
      "1068/1068 [==============================] - 0s 117us/step - loss: 0.3613 - mean_squared_error: 0.3613 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 961/1000\n",
      "1068/1068 [==============================] - 0s 112us/step - loss: 0.3178 - mean_squared_error: 0.3178 - val_loss: 0.7265 - val_mean_squared_error: 0.7265\n",
      "Epoch 962/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3123 - mean_squared_error: 0.3123 - val_loss: 0.7489 - val_mean_squared_error: 0.7489\n",
      "Epoch 963/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.7854 - val_mean_squared_error: 0.7854\n",
      "Epoch 964/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3554 - mean_squared_error: 0.3554 - val_loss: 0.7184 - val_mean_squared_error: 0.7184\n",
      "Epoch 965/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3252 - mean_squared_error: 0.3252 - val_loss: 0.7371 - val_mean_squared_error: 0.7371\n",
      "Epoch 966/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3054 - mean_squared_error: 0.3054 - val_loss: 0.7261 - val_mean_squared_error: 0.7261\n",
      "Epoch 967/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.2847 - mean_squared_error: 0.2847 - val_loss: 0.7465 - val_mean_squared_error: 0.7465\n",
      "Epoch 968/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3530 - mean_squared_error: 0.3530 - val_loss: 0.7106 - val_mean_squared_error: 0.7106\n",
      "Epoch 969/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3165 - mean_squared_error: 0.3165 - val_loss: 0.7482 - val_mean_squared_error: 0.7482\n",
      "Epoch 970/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3507 - mean_squared_error: 0.3507 - val_loss: 0.7133 - val_mean_squared_error: 0.7133\n",
      "Epoch 971/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.2832 - mean_squared_error: 0.2832 - val_loss: 0.7612 - val_mean_squared_error: 0.7612\n",
      "Epoch 972/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3339 - mean_squared_error: 0.3339 - val_loss: 0.7642 - val_mean_squared_error: 0.7642\n",
      "Epoch 973/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3338 - mean_squared_error: 0.3338 - val_loss: 0.7349 - val_mean_squared_error: 0.7349\n",
      "Epoch 974/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.7407 - val_mean_squared_error: 0.7407\n",
      "Epoch 975/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3312 - mean_squared_error: 0.3312 - val_loss: 0.7535 - val_mean_squared_error: 0.7535\n",
      "Epoch 976/1000\n",
      "1068/1068 [==============================] - 0s 92us/step - loss: 0.3258 - mean_squared_error: 0.3258 - val_loss: 0.7204 - val_mean_squared_error: 0.7204\n",
      "Epoch 977/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3008 - mean_squared_error: 0.3008 - val_loss: 0.7366 - val_mean_squared_error: 0.7366\n",
      "Epoch 978/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3765 - mean_squared_error: 0.3765 - val_loss: 0.7289 - val_mean_squared_error: 0.7289\n",
      "Epoch 979/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3340 - mean_squared_error: 0.3340 - val_loss: 0.7333 - val_mean_squared_error: 0.7333\n",
      "Epoch 980/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3284 - mean_squared_error: 0.3284 - val_loss: 0.7284 - val_mean_squared_error: 0.7284\n",
      "Epoch 981/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3476 - mean_squared_error: 0.3476 - val_loss: 0.7333 - val_mean_squared_error: 0.7333\n",
      "Epoch 982/1000\n",
      "1068/1068 [==============================] - 0s 94us/step - loss: 0.3321 - mean_squared_error: 0.3321 - val_loss: 0.7509 - val_mean_squared_error: 0.7509\n",
      "Epoch 983/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3209 - mean_squared_error: 0.3209 - val_loss: 0.7515 - val_mean_squared_error: 0.7515\n",
      "Epoch 984/1000\n",
      "1068/1068 [==============================] - 0s 95us/step - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.7479 - val_mean_squared_error: 0.7479\n",
      "Epoch 985/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3427 - mean_squared_error: 0.3427 - val_loss: 0.7323 - val_mean_squared_error: 0.7323\n",
      "Epoch 986/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3325 - mean_squared_error: 0.3325 - val_loss: 0.7498 - val_mean_squared_error: 0.7498\n",
      "Epoch 987/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.7451 - val_mean_squared_error: 0.7451\n",
      "Epoch 988/1000\n",
      "1068/1068 [==============================] - 0s 98us/step - loss: 0.3496 - mean_squared_error: 0.3496 - val_loss: 0.8068 - val_mean_squared_error: 0.8068\n",
      "Epoch 989/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3356 - mean_squared_error: 0.3356 - val_loss: 0.7300 - val_mean_squared_error: 0.7300\n",
      "Epoch 990/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3194 - mean_squared_error: 0.3194 - val_loss: 0.7484 - val_mean_squared_error: 0.7484\n",
      "Epoch 991/1000\n",
      "1068/1068 [==============================] - 0s 96us/step - loss: 0.3164 - mean_squared_error: 0.3164 - val_loss: 0.7168 - val_mean_squared_error: 0.7168\n",
      "Epoch 992/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3462 - mean_squared_error: 0.3462 - val_loss: 0.7574 - val_mean_squared_error: 0.7574\n",
      "Epoch 993/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3476 - mean_squared_error: 0.3476 - val_loss: 0.7333 - val_mean_squared_error: 0.7333\n",
      "Epoch 994/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3390 - mean_squared_error: 0.3390 - val_loss: 0.6950 - val_mean_squared_error: 0.6950\n",
      "Epoch 995/1000\n",
      "1068/1068 [==============================] - 0s 97us/step - loss: 0.3440 - mean_squared_error: 0.3440 - val_loss: 0.7347 - val_mean_squared_error: 0.7347\n",
      "Epoch 996/1000\n",
      "1068/1068 [==============================] - 0s 101us/step - loss: 0.3419 - mean_squared_error: 0.3419 - val_loss: 0.7313 - val_mean_squared_error: 0.7313\n",
      "Epoch 997/1000\n",
      "1068/1068 [==============================] - 0s 109us/step - loss: 0.3335 - mean_squared_error: 0.3335 - val_loss: 0.7576 - val_mean_squared_error: 0.7576\n",
      "Epoch 998/1000\n",
      "1068/1068 [==============================] - 0s 102us/step - loss: 0.3061 - mean_squared_error: 0.3061 - val_loss: 0.7173 - val_mean_squared_error: 0.7173\n",
      "Epoch 999/1000\n",
      "1068/1068 [==============================] - 0s 100us/step - loss: 0.3334 - mean_squared_error: 0.3334 - val_loss: 0.7746 - val_mean_squared_error: 0.7746\n",
      "Epoch 1000/1000\n",
      "1068/1068 [==============================] - 0s 99us/step - loss: 0.3164 - mean_squared_error: 0.3164 - val_loss: 0.7621 - val_mean_squared_error: 0.7621\n"
     ]
    }
   ],
   "source": [
    "#define criteria for early stop\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
    "\n",
    "# Train model\n",
    "training = model.fit(x1_train, y1_train, validation_split = 0.2,\n",
    "                     epochs=1000, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set using trained model\n",
    "y_pred = model.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mean_squared_error on test: 0.7850274475605569\n"
     ]
    }
   ],
   "source": [
    "#Mean_Squared_Error = MSE(y1_test, y_pred)\n",
    "print(\"model mean_squared_error on test: {}\".format(Mean_Squared_Error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_squared_error', 'loss', 'val_mean_squared_error', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(training.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'MSE')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training.history['loss'])\n",
    "plt.plot(training.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8202658],\n",
       "       [1.5246687],\n",
       "       [1.4007584],\n",
       "       [1.4027826],\n",
       "       [1.323352 ],\n",
       "       [2.188153 ],\n",
       "       [1.9676558],\n",
       "       [1.2451184],\n",
       "       [3.7565417],\n",
       "       [2.9050188]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 1, 1, 1, 2, 1, 5, 3], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
