{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find_files is given a directory. It creates a database containing the name and relative path for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " def find_files(subfolder_path):\n",
    "    #This code creates a database with every file and its path\n",
    "    dir = Path(os.getcwd())\n",
    "    #Add directory where your files are:\n",
    "    newdir = dir / subfolder_path\n",
    "\n",
    "\n",
    "    #subfolders = os.listdir(newdir)\n",
    "    subfolders = ['Train_data', 'Test_data']\n",
    "    dense_list = [os.listdir(newdir / subfolder) for subfolder in subfolders]\n",
    "    paired_list = zip(dense_list, subfolders)\n",
    "\n",
    "    audio_files = [(item, label) for sublist, label in paired_list for item in sublist]\n",
    "    audio_file_list, path_list = zip(*audio_files)\n",
    "    columns = ['file', 'relative_path']\n",
    "\n",
    "    common_prefix = os.path.commonprefix([dir, newdir])\n",
    "    relative_path = os.path.relpath(newdir, common_prefix)\n",
    "    print(relative_path)\n",
    "\n",
    "    #Using os.join.path and Path() leads to a Windows path, so I had to do it this way\n",
    "    relative_path = [relative_path + '/' + path for path in path_list]\n",
    "    print(relative_path)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    print(audio_file_list)\n",
    "    print(relative_path)\n",
    "    df.file = audio_file_list\n",
    "    df.relative_path = relative_path\n",
    "    return df\n",
    "\n",
    "# df.to_csv(dir / 'audio_database.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_representations\n",
      "['Feature_representations/Train_data', 'Feature_representations/Test_data']\n",
      "('Train_1.csv', 'Test_1.csv')\n",
      "['Feature_representations/Train_data', 'Feature_representations/Test_data']\n"
     ]
    }
   ],
   "source": [
    "df = find_files('Feature_representations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          file                       relative_path        test        train\n",
      "0  Train_1.csv  Feature_representations/Train_data         NaN  Train_1.csv\n",
      "1   Test_1.csv   Feature_representations/Test_data  Test_1.csv          NaN\n"
     ]
    }
   ],
   "source": [
    "test_ind = list(map(lambda x: 'test' in x, list(df['file'].apply(lambda x: x.lower()))))\n",
    "df['test'] = df['file'][[i for i, x in enumerate(test_ind) if x]]\n",
    "df['train'] = df['file'][[i for i, x in enumerate(test_ind) if not x]]\n",
    "# df.drop(['file'], axis = 1, inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loadGloveData takes the dimension of the Glove word vector as input. In creates a numpy version of the word vectors that is saved to the disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveData(cur_dim):\n",
    "\n",
    "    #%% Set path to Glove word vector folder\n",
    "    dir = Path(os.getcwd())\n",
    "    wvpack = \"glove.6B.\"+str(cur_dim)+\"d.txt\"\n",
    "    file_1 = dir / \"glove.6B\" / wvpack\n",
    "\n",
    "    df = pd.read_csv(file_1, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    WV = {key: val.values for key, val in df.T.items()}\n",
    "    file_2 = os.path.join(dir,'glove_dic','wv_dic_{}.npy'.format(cur_dim))\n",
    "    np.save(file_2, WV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\Documents\\GitHub\\Data Pipeline\\Test_data\n"
     ]
    }
   ],
   "source": [
    "dim = [50, 100, 200, 300]\n",
    "dir = Path(os.getcwd())\n",
    "print(dir)\n",
    "\n",
    "for example in dim:\n",
    "    fname = os.path.join(dir,'glove_dic','wv_dic_{}.npy'.format(example))\n",
    "    if not os.path.isfile(fname):\n",
    "        print(example)\n",
    "        loadGloveData(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create_train_test_w2v_matrices takes the dataframe containing the path to each train and test csv file, which is output by find_files. This function completes the processing required to create the word averaged representation of each piece of input data. The train and test sections coerce the input dataframe into the correct format, and the input is then feed to the docAveraging function. The final matrix representation is saved to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(*args):\n",
    "    cur_path = os.getcwd()\n",
    "    for value in args:\n",
    "        cur_path  = os.path.join(cur_path, value)\n",
    "    return cur_path\n",
    "\n",
    "class Data:\n",
    "    \n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    def __init__(self, file, rel_path):\n",
    "        self.quest_num = file[-5]\n",
    "        if 'test' in file.lower():\n",
    "            self.mat_type = 'test'\n",
    "            #Test Set\n",
    "            test = pd.read_csv(create_path(rel_path, file))\n",
    "            column_names = test.iloc[0,:]\n",
    "            test.drop([0], inplace=True)\n",
    "            test.rename(columns = column_names, inplace=True)\n",
    "            test.drop(columns = ['Section'], inplace=True)\n",
    "            test.dropna(inplace=True)\n",
    "            test['labels'] = test[test.columns[1:]].apply(\n",
    "                lambda x: ''.join(x.astype(str)),axis=1)\n",
    "            test.drop(column_names[2:], axis=1, inplace=True)\n",
    "            test.drop(test[test.labels=='eee'].index, inplace=True)\n",
    "            self.X = test['Dialogue'].apply(lambda x : x.lower().translate(Data.table))\n",
    "            self.Y = test['labels']\n",
    "        #Train set\n",
    "        elif 'train' in file.lower():\n",
    "            self.mat_type = 'train'\n",
    "            #Train set\n",
    "            train = pd.read_csv(create_path(rel_path, file))\n",
    "            train.drop([train.columns[0]], axis = 1, inplace=True)\n",
    "            train.dropna(inplace=True)\n",
    "            train['labels']=train.labels.apply(lambda x: ''.join([(3-len(str(x)))*'0',str(x)]))\n",
    "            self.X = train['Dialogue'].apply(lambda x : x.lower().translate(Data.table))\n",
    "            self.Y = train['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(Y, out_path):\n",
    "    if not os.path.isfile(out_path):\n",
    "        np.save(out_path, Y)\n",
    "\n",
    "def Create_TFIDF_matrices(df):\n",
    "    test_df = df[['test', 'relative_path']].dropna()\n",
    "    train_df = df[['train', 'relative_path']].dropna()\n",
    "    test_df.reset_index(inplace = True)\n",
    "    train_df.reset_index(inplace = True)\n",
    "    if len(test_df) <= len(train_df):\n",
    "        for i in range(min([len(test_df), len(train_df)])):  \n",
    "            train_data = Data(train_df.train[i], train_df.relative_path[i])\n",
    "# Attributes of train_data:   mat_type, quest_num, X_train, Y_train \n",
    "            #Sanity Check\n",
    "            if train_data.mat_type != 'train' or train_data.quest_num != str(i+1):\n",
    "                print('Expected matrix type train, received type {}'.format(train_data.mat_type))\n",
    "                print('Expected question # {}, received # {}'.format(i+1, train_data.quest_num))\n",
    "                print('error')\n",
    "            test_data = Data(test_df.test[i], test_df.relative_path[i])\n",
    "            #Sanity Check\n",
    "            if test_data.mat_type != 'test' or test_data.quest_num != str(i+1):\n",
    "                print('Expected matrix type test, received type {}'.format(test_data.mat_type))\n",
    "                print('Expected question # {}, received # {}'.format(i+1, test_data.quest_num))\n",
    "                print('error')\n",
    "            Y_train = train_data.Y\n",
    "            Y_test = test_data.Y\n",
    "            #Create TF-IDF Matrices (we want to tokenize the text before creating these)\n",
    "            X_train = train_data.X.apply(lambda x: word_tokenize(x))\n",
    "            X_test = test_data.X.apply(lambda x: word_tokenize(x))\n",
    "            #Flatten lists\n",
    "            X_train = [item for sublist in X_train for item in sublist]\n",
    "            X_test = [item for sublist in X_test for item in sublist]\n",
    "            print(X_test)\n",
    "            for dim in range (100, 200, 100): #max 2100\n",
    "                tfidf_vectorizer = TfidfVectorizer(max_features = dim)\n",
    "                tfidf_matrix = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "                tfidf_matrix_Test = tfidf_vectorizer.transform(X_test).toarray()\n",
    "                file_4 = create_path('tfidf_matrices','TFIDF_train_Question{}_{}dim.npy'.format(train_data.quest_num, dim))\n",
    "                file_5 = create_path('tfidf_matrices','TFIDF_test_Question{}_{}dim.npy'.format(test_data.quest_num, dim))\n",
    "                np.save(file_4, tfidf_matrix)\n",
    "                np.save(file_5, tfidf_matrix_Test)\n",
    "            save_labels(Y_train, create_path('labels', '{}_labels_question{}'.format(train_data.mat_type, train_data.quest_num)))\n",
    "            save_labels(Y_test, create_path('labels', '{}_labels_question{}'.format(test_data.mat_type, test_data.quest_num)))\n",
    "\n",
    "def Create_glove_w2v_matrices(df):\n",
    "    def docAveraging(sent, WV, dim):\n",
    "        summ = [0.0] * (dim)\n",
    "        A = 0.0;\n",
    "        sent_A = (re.sub(r\"[\\n(\\[\\])]\", \"\", sent)).split(\" \")\n",
    "        for word in sent_A:\n",
    "            if word in WV : #and word not in stop:\n",
    "                A = A + 1.0\n",
    "                for i in range(0, dim):\n",
    "                    summ[i] = summ[i] + float((WV[word])[i])\n",
    "        if A != 0:\n",
    "            #A = 1\n",
    "            for i in range(0, dim):\n",
    "                summ[i] = summ[i] / A\n",
    "        return summ;\n",
    "    \n",
    "    dim = [50, 100, 200, 300]\n",
    "    for i in range(len(df)): \n",
    "        file = df.file[i]\n",
    "        relative_path = df.relative_path[i]\n",
    "        mat_type, quest_num, X, Y =  load_data(file, relative_path)    \n",
    "        #Create w2v average matrices\n",
    "        for wvsize in dim:\n",
    "            file_2 = create_path('glove_dic','wv_dic_{}.npy'.format(wvsize))\n",
    "            WV = np.load(file_2).item() \n",
    "            ttMatrix = np.zeros((0, wvsize))\n",
    "            print('Current word vector size: {}'.format(wvsize))\n",
    "            print('Current question: {} {}'.format(mat_type, quest_num))\n",
    "            for train_doc in X:\n",
    "                ttMatrix = np.append(ttMatrix, [np.asarray(docAveraging(train_doc, WV, wvsize))], axis=0)#.decode('utf8').strip()), WV, dim))], axis=0)\n",
    "            file_3 = create_path('w2v_matrices','Question{}{}_{}dimensions.npy'.format(quest_num,mat_type,wvsize))\n",
    "            np.save(file_3, ttMatrix) \n",
    "            save_labels(Y, create_path(df.relative_path[i], '{}labels_question{}'.format(mat_type, quest_num)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'morning', 'mornin', 'capt', 'good', 'morning', 'capt', 'wang', 'i', 'am', 'here', 'to', 'discuss', 'with', 'you', 'and', 'the', 'platoon', 'about', 'important', 'business', 'hello', 'captain', 'wang', 'it', 'is', 'nice', 'to', 'see', 'you', 'this', 'morning', 'good', 'morning', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'meet', 'you', 'i', 'would', 'like', 'to', 'discuss', 'some', 'important', 'decisions', 'that', 'need', 'to', 'be', 'made', 'good', 'morning', 'sir', 'i', 'look', 'forward', 'to', 'giving', 'you', 'any', 'assistance', 'you', 'need', 'today', 'captain', 'wang', 'good', 'morning', 'good', 'morning', 'captain', 'wang', 'my', 'rank', 'may', 'be', 'lower', 'than', 'you', 'expected', 'but', 'i', 'speak', 'for', 'those', 'with', 'much', 'higher', 'rank', 'good', 'morning', 'captain', 'wang', 'how', 'are', 'you', 'doing', 'on', 'this', 'beautiful', 'day', 'i', 'am', 'pleased', 'to', 'meet', 'you', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'its', 'always', 'a', 'pleasure', 'to', 'see', 'you', 'and', 'i', 'am', 'delighted', 'we', 'will', 'be', 'working', 'together', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'you', 'may', 'have', 'noticed', 'my', 'ranking', 'and', 'i', 'am', 'fairly', 'young', 'but', 'i', 'can', 'assure', 'you', 'that', 'i', 'am', 'here', 'to', 'discuss', 'important', 'business', 'for', 'you', 'and', 'i', 'with', 'all', 'of', 'my', 'ability', 'to', 'help', 'hello', 'captain', 'wang', 'it', 'is', 'nice', 'to', 'meet', 'you', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'good', 'morning', 'captain', 'i', 'look', 'forward', 'to', 'working', 'with', 'you', 'sir', 'what', 'an', 'honor', 'it', 'is', 'to', 'meet', 'you', 'this', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'sir', 'my', 'name', 'is', 'jerry', 'lockley', 'and', 'i', 'am', 'honored', 'to', 'make', 'your', 'acquantaince', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'it', 'is', 'a', 'pleasue', 'to', 'meet', 'you', 'captain', 'wang', 'i', 'look', 'forward', 'to', 'working', 'with', 'you', 'good', 'morning', 'captain', 'wang', 'i', 'noticed', 'that', 'youre', 'looking', 'slightly', 'dissatisfied', 'with', 'my', 'ranking', 'as', 'a', 'soldier', 'but', 'i', 'can', 'assure', 'you', 'im', 'perfect', 'for', 'the', 'task', 'at', 'hand', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'good', 'morning', 'captain', 'wang', 'its', 'a', 'pleasure', 'to', 'meet', 'with', 'you', 'today', 'good', 'morning', 'captain', 'wang', 'sir', 'good', 'morning', 'captain', 'wang', 'captain', 'wang', 'good', 'morning', 'sir', 'ive', 'been', 'sent', 'as', 'a', 'representative', 'to', 'discuss', 'this', 'important', 'business', 'we', 'should', 'get', 'to', 'it', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'im', 'here', 'to', 'discuss', 'the', 'situation', 'at', 'hand', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'something', 'wrong', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'reporting', 'for', 'duty', 'good', 'morning', 'captain', 'wang', 'lets', 'get', 'to', 'business', 'hello', 'captain', 'wang', 'its', 'good', 'to', 'see', 'you', 'in', 'this', 'fine', 'morning', 'commander', 'good', 'morning', 'sir', 'good', 'morning', 'captain', 'wang', 'with', 'do', 'all', 'respect', 'sir', 'let', 'me', 'introduce', 'my', 'self', 'to', 'you', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'i', 'am', 'so', 'happy', 'to', 'finally', 'meet', 'you', 'good', 'morning', 'mr', 'wang', 'good', 'morning', 'captain', 'wang', 'i', 'look', 'forward', 'to', 'working', 'with', 'you', 'greetings', 'commander', 'hello', 'sir', 'how', 'are', 'you', 'doing', 'this', 'evening', 'hey', 'man', 'good', 'day', 'to', 'you', 'commander', 'good', 'day', 'to', 'you', 'and', 'also', 'how', 'are', 'you', 'today', 'this', 'meeting', 'should', 'proceed', 'hello', 'finally', 'nice', 'to', 'meet', 'you', 'hello', 'sir', 'how', 'are', 'you', 'doing', 'today', 'greetings', 'sir', 'good', 'to', 'meet', 'you', 'my', 'friend', 'good', 'day', 'to', 'you', 'how', 'are', 'you', 'doing', 'this', 'fine', 'day', 'you', 'look', 'very', 'happy', 'glad', 'to', 'see', 'you', 'hello', 'its', 'a', 'pleasure', 'to', 'meet', 'you', 'hello', 'its', 'a', 'pleasure', 'to', 'meet', 'you', 'how', 'are', 'you', 'doing', 'hi', 'good', 'day', 'commander', 'good', 'day', 'commander', 'it', 'is', 'an', 'honor', 'to', 'be', 'in', 'your', 'presence', 'how', 'are', 'you', 'good', 'day', 'i', 'am', 'very', 'honored', 'to', 'me', 'you', 'commandered', 'hello', 'i', 'hope', 'we', 'can', 'get', 'down', 'to', 'business', 'hello', 'sir', 'i', 'am', 'pleased', 'to', 'meet', 'you', 'hello', 'sir', 'how', 'are', 'you', 'doing', 'hello', 'good', 'morning', 'commander', 'hello', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'meet', 'you', 'good', 'morning', 'captain', 'wang', 'how', 'are', 'you', 'doing', 'today', 'sir', 'hello', 'captain', 'wang', 'is', 'everything', 'okay', 'your', 'face', 'has', 'me', 'worried', 'sir', 'hello', 'captain', 'wang', 'i', 'am', 'honored', 'to', 'meet', 'you', 'hello', 'captain', 'wang', 'how', 'are', 'you', 'today', 'hello', 'captain', 'wang', 'good', 'day', 'captain', 'wang', 'it', 'is', 'a', 'great', 'honor', 'to', 'meet', 'you', 'good', 'day', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'meet', 'you', 'i', 'hope', 'you', 'are', 'doing', 'well', 'today', 'hello', 'captain', 'wang', 'hello', 'captain', 'it', 'is', 'an', 'honor', 'to', 'be', 'meeting', 'with', 'you', 'sir', 'captain', 'wang', 'good', 'afternoon', 'how', 'are', 'you', 'and', 'your', 'soldiers', 'faring', 'today', 'captain', 'wang', 'good', 'morning', 'sir', 'its', 'an', 'honor', 'to', 'meet', 'you', 'captain', 'wang', 'im', 'honored', 'to', 'meet', 'you', 'captain', 'how', 'are', 'you', 'today', 'hello', 'captain', 'wang', 'nihao', 'captain', 'wang', 'pleasure', 'to', 'meet', 'you', 'nihao', 'captain', 'wang', 'pleasure', 'to', 'meet', 'you', 'how', 'was', 'your', 'trip', 'captain', 'captain', 'wang', 'good', 'morning', 'glad', 'to', 'meet', 'you', 'how', 'are', 'you', 'today', 'awesome', 'its', 'a', 'pleasure', 'to', 'meet', 'you', 'captain', 'wang', 'its', 'nice', 'to', 'meet', 'you', 'captain', 'how', 'are', 'you', 'doing', 'sir', 'greetings', 'captain', 'good', 'day', 'i', 'am', 'pleased', 'to', 'meet', 'you', 'captain', 'wang', 'i', 'am', 'pleased', 'to', 'meet', 'you', 'captain', 'wang', 'i', 'hope', 'you', 'are', 'well', 'nice', 'to', 'meet', 'you', 'good', 'afternoon', 'captain', 'wang', 'good', 'afternoon', 'captain', 'wang', 'how', 'are', 'you', 'today', 'hello', 'captain', 'hello', 'sir', 'sir', 'how', 'is', 'you', 'department', 'thank', 'you', 'sir', 'greetings', 'captain', 'wang', 'im', 'honored', 'that', 'you', 'joined', 'us', 'greetings', 'captain', 'wang', 'how', 'are', 'you', 'doing', 'today', 'greetings', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'good', 'day', 'captain', 'wang', 'how', 'are', 'you', 'feeling', 'today', 'i', 'dont', 'want', 'to', 'be', 'here', 'either', 'wang', 'its', 'a', 'pleasure', 'to', 'meet', 'you', 'captain', 'wang', 'hello', 'captain', 'good', 'evening', 'captain', 'wang', 'i', 'am', 'honored', 'to', 'meet', 'you', 'good', 'evening', 'how', 'have', 'you', 'been', 'recently', 'evening', 'commander', 'it', 'is', 'an', 'honor', 'to', 'meet', 'you', 'hello', 'commander', 'it', 'is', 'a', 'pleasure', 'to', 'meet', 'you', 'i', 'hope', 'all', 'is', 'well', 'with', 'your', 'company', 'greetings', 'commander', 'greetings', 'captain', 'greetings', 'captain', 'you', 'seem', 'discouraged', 'is', 'everything', 'alright', 'captain', 'sir', 'captain', 'wang', 'how', 'nice', 'it', 'is', 'to', 'see', 'you', 'commander', 'captain', 'wang', 'good', 'day', 'good', 'day', 'captain', 'wang', 'good', 'to', 'see', 'you', 'greetings', 'captain', 'wang', 'hello', 'captain', 'wang', 'how', 'are', 'you', 'today', 'good', 'morning', 'captain', 'wang', 'hello', 'captain', 'wang', 'its', 'a', 'great', 'honor', 'meet', 'with', 'you', 'to', 'discuss', 'these', 'important', 'matters', 'greetings', 'captain', 'wang', 'its', 'an', 'honor', 'and', 'a', 'privilege', 'to', 'meet', 'with', 'you', 'how', 'was', 'your', 'travel', 'to', 'get', 'here', 'captain', 'wang', 'hi', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'how', 'are', 'you', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'have', 'you', 'with', 'us', 'good', 'morning', 'captain', 'wang', 'how', 'are', 'you', 'today', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'i', 'am', 'pleased', 'to', 'have', 'this', 'meeting', 'with', 'you', 'good', 'morning', 'captain', 'wang', 'is', 'everything', 'going', 'well', 'for', 'you', 'so', 'far', 'greetings', 'captain', 'wang', 'captain', 'wong', 'it', 'is', 'my', 'honor', 'to', 'have', 'you', 'join', 'us', 'on', 'this', 'good', 'morning', 'how', 'are', 'you', 'doing', 'today', 'on', 'this', 'good', 'morning', 'captain', 'wong', 'captain', 'wong', 'good', 'morning', 'good', 'morning', 'captain', 'wang', 'it', 'is', 'an', 'honer', 'to', 'have', 'you', 'grace', 'us', 'with', 'your', 'presence', 'good', 'morning', 'captain', 'wang', 'how', 'is', 'everything', 'today', 'morning', 'captain', 'wang', 'hello', 'captain', 'wang', 'its', 'an', 'honor', 'to', 'have', 'you', 'here', 'greeting', 'captain', 'wang', 'how', 'goes', 'today', 'for', 'you', 'pleasant', 'morning', 'captain', 'wang', 'captain', 'wang', 'good', 'morning', 'i', 'am', 'honored', 'by', 'your', 'presence', 'how', 'are', 'you', 'this', 'morning', 'captain', 'wang', 'captain', 'wang', 'i', 'hope', 'you', 'are', 'having', 'a', 'good', 'morning', 'i', 'am', 'honored', 'you', 'joined', 'us', 'captain', 'how', 'are', 'you', 'this', 'morning', 'captain', 'wang', 'hope', 'you', 'are', 'doing', 'good', 'this', 'morning', 'captain', 'good', 'morning', 'i', 'am', 'glad', 'to', 'have', 'you', 'with', 'us', 'today', 'goodday', 'how', 'are', 'you', 'doing', 'today', 'captain', 'wang', 'top', 'of', 'the', 'morning', 'to', 'ya', 'good', 'morning', 'captain', 'wang', 'i', 'am', 'honored', 'to', 'meet', 'with', 'you', 'good', 'morning', 'captain', 'wang', 'how', 'is', 'your', 'day', 'so', 'far', 'captain', 'wang', 'good', 'morning', 'good', 'morning', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'have', 'you', 'join', 'us', 'good', 'morning', 'captain', 'wang', 'how', 'is', 'your', 'day', 'hello', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'have', 'you', 'join', 'us', 'captain', 'wang', 'how', 'are', 'you', 'today', 'caption', 'wang', 'good', 'morning', 'and', 'how', 'are', 'you', 'captain', 'wang', 'good', 'to', 'see', 'you', 'this', 'morning', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'have', 'you', 'join', 'us', 'here', 'captain', 'wang', 'good', 'morning', 'a', 'very', 'good', 'morning', 'to', 'you', 'captain', 'wang', 'how', 'are', 'you', 'feeling', 'today', 'hello', 'captain', 'wang', 'good', 'morning', 'you', 'im', 'honored', 'to', 'have', 'you', 'with', 'us', 'this', 'morning', 'captain', 'wang', 'how', 'are', 'you', 'fairing', 'this', 'morning', 'captain', 'wang', 'i', 'hope', 'your', 'morning', 'has', 'been', 'good', 'captain', 'wang', 'good', 'morning', 'captain', 'i', 'am', 'sincerely', 'honored', 'to', 'have', 'you', 'with', 'us', 'good', 'morning', 'to', 'you', 'captain', 'wang', 'how', 'are', 'you', 'this', 'morning', 'greetings', 'captain', 'wang', 'morning', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'for', 'you', 'to', 'be', 'here', 'with', 'us', 'good', 'day', 'captain', 'wang', 'how', 'are', 'you', 'top', 'of', 'the', 'morning', 'captain', 'wang', 'welcome', 'captain', 'wang', 'it', 'is', 'an', 'honor', 'to', 'have', 'you', 'here', 'with', 'us', 'good', 'morning', 'captain', 'wang', 'how', 'are', 'you', 'hello', 'captain', 'wang', 'captain', 'wang', 'good', 'morning', 'we', 'are', 'honored', 'that', 'you', 'would', 'take', 'time', 'to', 'join', 'us', 'this', 'day', 'good', 'morning', 'how', 'are', 'you', 'today', 'captain', 'wang', 'hello', 'captain', 'wang', 'good', 'to', 'see', 'you', 'this', 'morning', 'captain', 'wang', 'good', 'morning', 'i', 'am', 'greatly', 'honored', 'to', 'be', 'your', 'host', 'good', 'morning', 'captain', 'wang', 'i', 'trust', 'that', 'you', 'are', 'well', 'today', 'pleasant', 'day', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'i', 'am', 'honored', 'to', 'have', 'you', 'with', 'us', 'good', 'morning', 'captain', 'how', 'are', 'you', 'hi', 'captain', 'wang', 'good', 'morning', 'i', 'am', 'happy', 'to', 'have', 'you', 'join', 'us', 'this', 'morning', 'captain', 'wang', 'how', 'are', 'doing', 'this', 'morning', 'captain', 'wang', 'a', 'very', 'good', 'morning', 'to', 'you', 'captain', 'wang', 'greetings', 'captain', 'wang', 'its', 'a', 'pleasure', 'to', 'have', 'you', 'around', 'greetings', 'captain', 'wang', 'i', 'hope', 'you', 'are', 'well', 'this', 'morning', 'how', 'are', 'you', 'this', 'morning', 'captain', 'wang', 'good', 'day', 'captain', 'wang', 'its', 'an', 'honor', 'to', 'have', 'you', 'here', 'with', 'us', 'captain', 'wang', 'good', 'morning', 'are', 'you', 'doing', 'well', 'today', 'captain', 'wang', 'good', 'day', 'to', 'you', 'i', 'am', 'honored', 'to', 'have', 'you', 'join', 'us', 'this', 'morning', 'captain', 'wang', 'good', 'morning', 'how', 'are', 'you', 'doing', 'today', 'captain', 'wang', 'good', 'morning', 'captain', 'wang', 'good', 'morning', 'captain', 'wanghope', 'you', 'are', 'doing', 'good', 'captain', 'wang', 'are', 'you', 'okay']\n"
     ]
    }
   ],
   "source": [
    "Create_TFIDF_matrices(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\Documents\\GitHub\\Data Pipeline\\Test_data\\hello\\chicken\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cur_path = create_path('hello', 'chicken')\n",
    "print(cur_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(create_path('feature_representations', 'Features', 'alkdsfdsajf.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
